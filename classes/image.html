<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>dbdicom.classes.image API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>dbdicom.classes.image</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">__all__ = [&#39;QImage&#39;]

import os
import struct
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import nibabel as nib
from matplotlib import cm
from nibabel.affines import apply_affine
from PyQt5 import QtGui

from .instance import Instance

class Image(Instance):
    &#34;&#34;&#34;Specific methods for the SOPClass MR Image Storage&#34;&#34;&#34;

    def _initialize(self, ref_ds=None):
        &#34;&#34;&#34;Initialize the attributes relevant for the Images&#34;&#34;&#34;

        super()._initialize(ref_ds)
        
        self.ImageType.insert(0, &#34;DERIVED&#34;)

    def array(self):
        &#34;&#34;&#34;Read the pixel array from an image&#34;&#34;&#34;

        on_disk = self.on_disk()
        if on_disk: self.read()
        if self.ds is None: return
        array = self.ds.pixel_array.astype(np.float32)
        slope = float(getattr(self.ds, &#39;RescaleSlope&#39;, 1)) 
        intercept = float(getattr(self.ds, &#39;RescaleIntercept&#39;, 0)) 
        #array = array * slope + intercept
        array *= slope
        array += intercept
        array = np.transpose(array)
        if on_disk: self.clear()
        return array

    def set_array(self, array, value_range=None):

        on_disk = self.on_disk()
        if on_disk: self.read()
        
        if array.ndim &gt;= 3: # remove spurious dimensions of 1
            array = np.squeeze(array) 
        array = self.clip(array, value_range=value_range)
        array, slope, intercept = self.scale_to_range(array, self.ds.BitsAllocated)
        array = np.transpose(array)

        maximum = np.amax(array)
        minimum = np.amin(array)
        shape = np.shape(array)

        self.ds.PixelRepresentation = 0
        self.ds.SmallestImagePixelValue = int(maximum)
        self.ds.LargestImagePixelValue = int(minimum)
        self.ds.RescaleSlope = 1 / slope
        self.ds.RescaleIntercept = - intercept / slope
#        self.ds.WindowCenter = (maximum + minimum) / 2
#        self.ds.WindowWidth = maximum - minimum
        self.ds.Rows = shape[0]
        self.ds.Columns = shape[1]
        self.ds.PixelData = array.tobytes()
        if on_disk: 
            self.write()
            self.clear()

#    def write_array(self, pixelArray, value_range=None): # obsolete - remove
#        &#34;&#34;&#34;Write the pixel array to disk&#34;&#34;&#34;
#        self.set_array(pixelArray, value_range=value_range)
#        self.write()

    def clip(self, array, value_range = None):

        array[np.isnan(array)] = 0
        if value_range is None:
            finite = array[np.isfinite(array)]
            value_range = [np.amin(finite), np.amax(finite)]
        return np.clip(array, value_range[0], value_range[1])

    def scale_to_range(self, array, bits_allocated):
            
    #    target = np.power(2, bits_allocated) - 1
        target = 2.0**bits_allocated - 1
        maximum = np.amax(array)
        minimum = np.amin(array)
        if maximum == minimum:
            slope = 1
        else:
            slope = target / (maximum - minimum)
        intercept = -slope * minimum
        # array = slope * (array - minimum)
        array = slope * array + intercept

        if bits_allocated == 8:
            return array.astype(np.uint8), slope, intercept
        if bits_allocated == 16:
            return array.astype(np.uint16), slope, intercept
        if bits_allocated == 32:
            return array.astype(np.uint32), slope, intercept
        if bits_allocated == 64:
            return array.astype(np.uint64), slope, intercept

    def zeros(self):

        array = np.zeros((self.Rows, self.Columns))
        new = self.copy()
    #    new.write_array(array)
        new.set_array(array)
        new.write()
        return new

    def map_onto(self, target):
        &#34;&#34;&#34;Map non-zero image pixels onto a target image.
        
        Overwrite pixel values in the target&#34;&#34;&#34;

        # Create a coordinate array of non-zero pixels
        coords = np.transpose(np.where(self.array() != 0)) 
        coords = [[coord[0], coord[1], 0] for coord in coords] 
        coords = np.array(coords)

        # Determine coordinate transformation matrix
        affineSource = self.affine_matrix()
        affineTarget = target.affine_matrix()
        sourceToTarget = np.linalg.inv(affineTarget).dot(affineSource)

        # Apply coordinate transformation
        coords = apply_affine(sourceToTarget, coords)
        coords = np.round(coords, 3).astype(int)
        x = tuple([coord[0] for coord in coords if coord[2] == 0])
        y = tuple([coord[1] for coord in coords if coord[2] == 0])

        # Set values in the target image
        # Note - replace by actual values rather than 1 &amp; 0.
        result = target.zeros()
        in_memory = self.in_memory()
        if in_memory: result.read()
        pixelArray = result.array()
        pixelArray[(x, y)] = 1.0
        result.set_array(pixelArray)
        if not in_memory: 
            result.write()
            result.clear()

        return result

    def affine_matrix(self):
        &#34;&#34;&#34;Affine transformation matrix for a DICOM image&#34;&#34;&#34;

        on_disk = self.on_disk()
        if on_disk: self.read()

        image_orientation = self.ds.ImageOrientationPatient
        image_position = self.ds.ImagePositionPatient
        pixel_spacing = self.ds.PixelSpacing
        slice_spacing = self.ds.SliceThickness            

        row_spacing = pixel_spacing[0]
        column_spacing = pixel_spacing[1]

        row_cosine = np.array(image_orientation[:3])
        column_cosine = np.array(image_orientation[3:])
        slice_cosine = np.cross(row_cosine, column_cosine)

        affine = np.identity(4, dtype=np.float32)
        affine[:3, 0] = row_cosine * column_spacing
        affine[:3, 1] = column_cosine * row_spacing
        affine[:3, 2] = slice_cosine * slice_spacing
        affine[:3, 3] = image_position

        if on_disk: self.clear()

        return affine

    def get_colormap(self):
        &#34;&#34;&#34;Returns the colormap if there is any.&#34;&#34;&#34;

        on_disk = self.on_disk()
        if on_disk: self.read()
        ds = self.ds

        lut = None
        if hasattr(ds, &#39;ContentLabel&#39;):
            if ds.PhotometricInterpretation == &#39;PALETTE COLOR&#39;:
                colormap = ds.ContentLabel
            elif &#39;MONOCHROME&#39; in ds.PhotometricInterpretation:
                colormap = &#39;gray&#39;
        elif len(ds.dir(&#34;PaletteColor&#34;))&gt;=3 and ds.PhotometricInterpretation == &#39;PALETTE COLOR&#39;:
            colormap = &#39;custom&#39;
            lut = self.get_lut()
        else:
            colormap = &#39;gray&#39; # default

        if on_disk: self.clear()
        return colormap, lut  

    def get_lut(self):
        
        on_disk = self.on_disk()
        if on_disk: self.read()
        ds = self.ds

        redColour = list(ds.RedPaletteColorLookupTableData)
        greenColour = list(ds.GreenPaletteColorLookupTableData)
        blueColour = list(ds.BluePaletteColorLookupTableData)
        redLut = list(struct.unpack(&#39;&lt;&#39; + (&#39;H&#39; * ds.RedPaletteColorLookupTableDescriptor[0]), bytearray(redColour)))
        greenLut = list(struct.unpack(&#39;&lt;&#39; + (&#39;H&#39; * ds.GreenPaletteColorLookupTableDescriptor[0]), bytearray(greenColour)))
        blueLut = list(struct.unpack(&#39;&lt;&#39; + (&#39;H&#39; * ds.BluePaletteColorLookupTableDescriptor[0]), bytearray(blueColour)))
        colours = np.transpose([redLut, greenLut, blueLut])
        normaliseFactor = int(np.power(2, ds.RedPaletteColorLookupTableDescriptor[2]))
        # Fast ColourTable loading
        colourTable = np.around(colours/normaliseFactor, decimals = 2)
        indexes = np.unique(colourTable, axis=0, return_index=True)[1]
        lut = [colourTable[index].tolist() for index in sorted(indexes)]
        # Full / Complete Colourmap - takes 20 seconds to load each image
        # lut = (colours/normaliseFactor).tolist()   
        if on_disk: self.clear()
        return lut      

    def set_colormap(self, colormap=None, levels=None):
        &#34;&#34;&#34;Set the colour table of the image.&#34;&#34;&#34;

        on_disk = self.on_disk()
        if on_disk: self.read()
        ds = self.ds

        #and (colormap != &#39;gray&#39;) removed from If statement below, so as to save gray colour tables
        if (colormap == &#39;gray&#39;):
            ds.PhotometricInterpretation = &#39;MONOCHROME2&#39;
            ds.ContentLabel = &#39;&#39;
            if hasattr(ds, &#39;RedPaletteColorLookupTableData&#39;):
                del (ds.RGBLUTTransferFunction, ds.RedPaletteColorLookupTableData,
                    ds.GreenPaletteColorLookupTableData, ds.BluePaletteColorLookupTableData,
                    ds.RedPaletteColorLookupTableDescriptor, ds.GreenPaletteColorLookupTableDescriptor,
                    ds.BluePaletteColorLookupTableDescriptor)
        if ((colormap is not None)  and (colormap != &#39;custom&#39;) and (colormap != &#39;gray&#39;) 
            and (colormap != &#39;default&#39;) and isinstance(colormap, str)):
            ds.PhotometricInterpretation = &#39;PALETTE COLOR&#39;
            ds.RGBLUTTransferFunction = &#39;TABLE&#39;
            ds.ContentLabel = colormap
            stringType = &#39;US&#39; # (&#39;SS&#39; if minValue &lt; 0 else &#39;US&#39;)
            ds.PixelRepresentation = 0 # (1 if minValue &lt; 0 else 0)
            pixelArray = ds.pixel_array
            minValue = int(np.amin(pixelArray))
            maxValue = int(np.amax(pixelArray))
            numberOfValues = int(maxValue - minValue)
            arrayForRGB = np.arange(0, numberOfValues)
            colorsList = cm.ScalarMappable(cmap=colormap).to_rgba(np.array(arrayForRGB), bytes=False)
            totalBytes = ds.BitsAllocated
            ds.add_new(&#39;0x00281101&#39;, stringType, [numberOfValues, minValue, totalBytes])
            ds.add_new(&#39;0x00281102&#39;, stringType, [numberOfValues, minValue, totalBytes])
            ds.add_new(&#39;0x00281103&#39;, stringType, [numberOfValues, minValue, totalBytes])
            ds.RedPaletteColorLookupTableData = bytes(np.array([int((np.power(
                2, totalBytes) - 1) * value) for value in colorsList[:, 0].flatten()]).astype(&#39;uint&#39;+str(totalBytes)))
            ds.GreenPaletteColorLookupTableData = bytes(np.array([int((np.power(
                2, totalBytes) - 1) * value) for value in colorsList[:, 1].flatten()]).astype(&#39;uint&#39;+str(totalBytes)))
            ds.BluePaletteColorLookupTableData = bytes(np.array([int((np.power(
                2, totalBytes) - 1) * value) for value in colorsList[:, 2].flatten()]).astype(&#39;uint&#39;+str(totalBytes)))
        if levels is not None:
            ds.WindowCenter = levels[0]
            ds.WindowWidth = levels[1]
        if on_disk: self.clear()

    def export_as_nifti(self, directory=None, filename=None):
        &#34;&#34;&#34;Export 2D pixel Array in nifty format&#34;&#34;&#34;

        on_disk = self.on_disk()
        if on_disk: self.read()
        ds = self.ds
        if directory is None: 
            directory = self.directory(message=&#39;Please select a folder for the nifty data&#39;)
        if filename is None:
            filename = self.SeriesDescription
        dicomHeader = nib.nifti1.Nifti1DicomExtension(2, ds)
        niftiObj = nib.Nifti1Instance(np.flipud(np.rot90(np.transpose(self.array()))), affine=self.affine)
        # The transpose is necessary in this case to be in line with the rest of WEASEL.
        niftiObj.header.extensions.append(dicomHeader)
        nib.save(niftiObj, directory + &#39;/&#39; + filename + &#39;.nii.gz&#39;)
        if on_disk: self.clear()

    def export_as_csv(self, directory=None, filename=None, columnHeaders=None):
        &#34;&#34;&#34;Export 2D pixel Array in csv format&#34;&#34;&#34;

        if directory is None: 
            directory = self.directory(message=&#39;Please select a folder for the csv data&#39;)
        if filename is None:
            filename = self.SeriesDescription
        filename = os.path.join(directory, filename + &#39;.csv&#39;)
        table = self.array()
        if columnHeaders is None:
            columnHeaders = []
            counter = 0
            for _ in table:
                counter += 1
                columnHeaders.append(&#34;Column&#34; + str(counter))
        df = pd.DataFrame(np.transpose(table), columns=columnHeaders)
        df.to_csv(filename, index=False) 

    def export_as_png(self, fileName):
        &#34;&#34;&#34;Export image in png format.&#34;&#34;&#34;

        colourTable, _ = self.get_colormap()
        pixelArray = np.transpose(self.array())
        centre, width = self.window()
        minValue = centre - width/2
        maxValue = centre + width/2
        cmap = plt.get_cmap(colourTable)
        plt.imshow(pixelArray, cmap=cmap)
        plt.clim(int(minValue), int(maxValue))
        cBar = plt.colorbar()
        cBar.minorticks_on()
        plt.savefig(fname=fileName + &#39;_&#39; + self.label() + &#39;.png&#39;)
        plt.close()

    def window(self):
        &#34;&#34;&#34;Centre and width of the pixel data after applying rescale slope and intercept&#34;&#34;&#34;

        on_disk = self.on_disk()
        if on_disk: self.read()
        if &#39;WindowCenter&#39; in self.ds: centre = self.ds.WindowCenter
        if &#39;WindowWidth&#39; in self.ds: width = self.ds.WindowWidth
        if centre is None or width is None:
            array = self.array()
        if centre is None: 
            centre = np.median(array)
        if width is None: 
            p = np.percentile(array, [25, 75])
            width = p[1] - p[0]
        if on_disk: self.clear()
        return centre, width

    def QImage(self):

        array = self.array()
        return QImage(array, width=self.WindowWidth, center=self.WindowCenter)


def QImage(array, width=None, center=None):

    if (width is None) or (center is None):
        max = np.amax(array)
        min = np.amin(array)
    if width is None: width = max-min
    if center is None: center = (max-min)/2

    imgData, alpha = _makeARGB(
        data = array, 
        levels = [center-width/2, center+width/2],
    )
    return _makeQImage(imgData, alpha)


# HELPER FUNCTIONS ADAPTED FROM pyQtGraph


def _makeARGB(data, lut=None, levels=None, scale=None, useRGBA=False): 
    &#34;&#34;&#34; 
    Convert an array of values into an ARGB array suitable for building QImages
    
    Returns the ARGB array (unsigned byte) and a boolean indicating whether
    there is alpha channel data. This is a two stage process:
    
        1) Rescale the data based on the values in the *levels* argument (min, max).
        2) Determine the final output by passing the rescaled values through a
           lookup table.
   
    Both stages are optional.
    
    ============== ==================================================================================
    **Arguments:**
    data           numpy array of int/float types. If 
    levels         List [min, max]; optionally rescale data before converting through the
                   lookup table. The data is rescaled such that min-&gt;0 and max-&gt;*scale*::
                   
                      rescaled = (clip(data, min, max) - min) * (*scale* / (max - min))
                   
                   It is also possible to use a 2D (N,2) array of values for levels. In this case,
                   it is assumed that each pair of min,max values in the levels array should be 
                   applied to a different subset of the input data (for example, the input data may 
                   already have RGB values and the levels are used to independently scale each 
                   channel). The use of this feature requires that levels.shape[0] == data.shape[-1].
    scale          The maximum value to which data will be rescaled before being passed through the 
                   lookup table (or returned if there is no lookup table). By default this will
                   be set to the length of the lookup table, or 255 if no lookup table is provided.
    lut            Optional lookup table (array with dtype=ubyte).
                   Values in data will be converted to color by indexing directly from lut.
                   The output data shape will be input.shape + lut.shape[1:].
                   Lookup tables can be built using ColorMap or GradientWidget.
    useRGBA        If True, the data is returned in RGBA order (useful for building OpenGL textures). 
                   The default is False, which returns in ARGB order for use with QImage 
                   (Note that &#39;ARGB&#39; is a term used by the Qt documentation; the *actual* order 
                   is BGRA).
    ============== ==================================================================================
    &#34;&#34;&#34;

    if data.ndim not in (2, 3):
        raise TypeError(&#34;data must be 2D or 3D&#34;)
    if data.ndim == 3 and data.shape[2] &gt; 4:
        raise TypeError(&#34;data.shape[2] must be &lt;= 4&#34;)
    
    if lut is not None and not isinstance(lut, np.ndarray):
        lut = np.array(lut)
    
    if levels is None:
        # automatically decide levels based on data dtype
        if data.dtype.kind == &#39;u&#39;:
            levels = np.array([0, 2**(data.itemsize*8)-1])
        elif data.dtype.kind == &#39;i&#39;:
            s = 2**(data.itemsize*8 - 1)
            levels = np.array([-s, s-1])
        elif data.dtype.kind == &#39;b&#39;:
            levels = np.array([0,1])
        else:
            raise Exception(&#39;levels argument is required for float input types&#39;)
    if not isinstance(levels, np.ndarray):
        levels = np.array(levels)
    if levels.ndim == 1:
        if levels.shape[0] != 2:
            raise Exception(&#39;levels argument must have length 2&#39;)
    elif levels.ndim == 2:
        if lut is not None and lut.ndim &gt; 1:
            raise Exception(&#39;Cannot make ARGB data when both levels and lut have ndim &gt; 2&#39;)
        if levels.shape != (data.shape[-1], 2):
            raise Exception(&#39;levels must have shape (data.shape[-1], 2)&#39;)
    else:
        raise Exception(&#34;levels argument must be 1D or 2D (got shape=%s).&#34; % repr(levels.shape))

    # Decide on maximum scaled value
    if scale is None:
        if lut is not None:
            scale = lut.shape[0] - 1
        else:
            scale = 255.

    # Decide on the dtype we want after scaling
    if lut is None:
        dtype = np.ubyte
    else:
        dtype = np.min_scalar_type(lut.shape[0]-1)
            
    # Apply levels if given
    if levels is not None:
        if isinstance(levels, np.ndarray) and levels.ndim == 2:
            # we are going to rescale each channel independently
            if levels.shape[0] != data.shape[-1]:
                raise Exception(&#34;When rescaling multi-channel data, there must be the same number of levels as channels (data.shape[-1] == levels.shape[0])&#34;)
            newData = np.empty(data.shape, dtype=int)
            for i in range(data.shape[-1]):
                minVal, maxVal = levels[i]
                if minVal == maxVal:
                    maxVal += 1e-16
                newData[...,i] = _rescaleData(data[...,i], scale/(maxVal-minVal), minVal, dtype=dtype)
            data = newData
        else:
            # Apply level scaling unless it would have no effect on the data
            minVal, maxVal = levels
            if minVal != 0 or maxVal != scale:
                if minVal == maxVal:
                    maxVal += 1e-16
                data = _rescaleData(data, scale/(maxVal-minVal), minVal, dtype=dtype)
            
    # apply LUT if given
    if lut is not None:
        data = _applyLookupTable(data, lut)
    else:
        if data.dtype is not np.ubyte:
            data = np.clip(data, 0, 255).astype(np.ubyte)

    # this will be the final image array
    imgData = np.empty(data.shape[:2]+(4,), dtype=np.ubyte)

    # decide channel order
    if useRGBA:
        order = [0,1,2,3] # array comes out RGBA
    else:
        order = [2,1,0,3] # for some reason, the colors line up as BGR in the final image.
        
    # copy data into image array
    if data.ndim == 2:
        # This is tempting:
        #   imgData[..., :3] = data[..., np.newaxis]
        # ..but it turns out this is faster:
        for i in range(3):
            imgData[..., i] = data
    elif data.shape[2] == 1:
        for i in range(3):
            imgData[..., i] = data[..., 0]
    else:
        for i in range(0, data.shape[2]):
            imgData[..., i] = data[..., order[i]] 
    
    # add opaque alpha channel if needed
    if data.ndim == 2 or data.shape[2] == 3:
        alpha = False
        imgData[..., 3] = 255
    else:
        alpha = True

    return imgData, alpha


def _makeQImage(imgData, alpha=None, copy=True, transpose=True):
    &#34;&#34;&#34;
    Turn an ARGB array into QImage. &#39;d
    By default, the data is copied; changes to the array will not
    be reflected in the image. The image will be given aata&#39; attribute
    pointing to the array which shares its data to prevent python
    freeing that memory while the image is in use.
    
    ============== ===================================================================
    **Arguments:**
    imgData        Array of data to convert. Must have shape (width, height, 3 or 4) 
                   and dtype=ubyte. The order of values in the 3rd axis must be 
                   (b, g, r, a).
    alpha          If True, the QImage returned will have format ARGB32. If False,
                   the format will be RGB32. By default, _alpha_ is True if
                   array.shape[2] == 4.
    copy           If True, the data is copied before converting to QImage.
                   If False, the new QImage points directly to the data in the array.
                   Note that the array must be contiguous for this to work
                   (see numpy.ascontiguousarray).
    transpose      If True (the default), the array x/y axes are transposed before 
                   creating the image. Note that Qt expects the axes to be in 
                   (height, width) order whereas pyqtgraph usually prefers the 
                   opposite.
    ============== ===================================================================    
    &#34;&#34;&#34;
    ## create QImage from buffer
    
    ## If we didn&#39;t explicitly specify alpha, check the array shape.
    if alpha is None:
        alpha = (imgData.shape[2] == 4)
        
    copied = False
    if imgData.shape[2] == 3:  ## need to make alpha channel (even if alpha==False; QImage requires 32 bpp)
        if copy is True:
            d2 = np.empty(imgData.shape[:2] + (4,), dtype=imgData.dtype)
            d2[:,:,:3] = imgData
            d2[:,:,3] = 255
            imgData = d2
            copied = True
        else:
            raise Exception(&#39;Array has only 3 channels; cannot make QImage without copying.&#39;)
    
    if alpha:
        imgFormat = QtGui.QImage.Format_ARGB32
    else:
        imgFormat = QtGui.QImage.Format_RGB32
        
    if transpose:
        imgData = imgData.transpose((1, 0, 2))  ## QImage expects the row/column order to be opposite

    if not imgData.flags[&#39;C_CONTIGUOUS&#39;]:
        if copy is False:
            extra = &#39; (try setting transpose=False)&#39; if transpose else &#39;&#39;
            raise Exception(&#39;Array is not contiguous; cannot make QImage without copying.&#39;+extra)
        imgData = np.ascontiguousarray(imgData)
        copied = True
        
    if copy is True and copied is False:
        imgData = imgData.copy()       
    try:
        img = QtGui.QImage(imgData.ctypes.data, imgData.shape[1], imgData.shape[0], imgFormat)
    except:
        img = QtGui.QImage(memoryview(imgData), imgData.shape[1], imgData.shape[0], imgFormat)
                
    img.data = imgData
    
    return img
    
def _applyLookupTable(data, lut):
    &#34;&#34;&#34;
    Uses values in *data* as indexes to select values from *lut*.
    The returned data has shape data.shape + lut.shape[1:]
    &#34;&#34;&#34;
    if data.dtype.kind not in (&#39;i&#39;, &#39;u&#39;):
        data = data.astype(int)
    
    return np.take(lut, data, axis=0, mode=&#39;clip&#39;)  


def _rescaleData(data, scale, offset, dtype=None, clip=None):
    &#34;&#34;&#34;Return data rescaled and optionally cast to a new dtype::
    
        data =&gt; (data-offset) * scale
        
    &#34;&#34;&#34;
    if dtype is None:
        dtype = data.dtype
    else:
        dtype = np.dtype(dtype)
    
    try:
        newData = np.empty((data.size,), dtype=dtype)
        flat = np.ascontiguousarray(data).reshape(data.size)
        newData = (flat - offset)*scale 
        if dtype != dtype: 
            newData = newData.astype(dtype)
        data = newData.reshape(data.shape)
    except:
        
        d2 = data - float(offset)
        d2 *= scale
        
        # Clip before converting dtype to avoid overflow
        if dtype.kind in &#39;ui&#39;:
            lim = np.iinfo(dtype)
            if clip is None:
                # don&#39;t let rescale cause integer overflow
                d2 = np.clip(d2, lim.min, lim.max)
            else:
                d2 = np.clip(d2, max(clip[0], lim.min), min(clip[1], lim.max))
        else:
            if clip is not None:
                d2 = np.clip(d2, *clip)
        data = d2.astype(dtype)
    return data</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="dbdicom.classes.image.QImage"><code class="name flex">
<span>def <span class="ident">QImage</span></span>(<span>array, width=None, center=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def QImage(array, width=None, center=None):

    if (width is None) or (center is None):
        max = np.amax(array)
        min = np.amin(array)
    if width is None: width = max-min
    if center is None: center = (max-min)/2

    imgData, alpha = _makeARGB(
        data = array, 
        levels = [center-width/2, center+width/2],
    )
    return _makeQImage(imgData, alpha)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="dbdicom.classes" href="index.html">dbdicom.classes</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="dbdicom.classes.image.QImage" href="#dbdicom.classes.image.QImage">QImage</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>