<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>dbdicom.classes.record API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>dbdicom.classes.record</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import os
from copy import deepcopy
import pydicom
import numpy as np
import pandas as pd
from .. import utilities
import dbdicom as db


class Record():

    def __init__(self, folder, UID=[], generation=0, **attributes):

        objUID = [] + UID
#        for i in range(generation-len(UID)):
        while generation &gt; len(objUID):
            newUID = pydicom.uid.generate_uid()
            objUID.append(newUID)    

        self.__dict__[&#39;UID&#39;] = objUID
        self.__dict__[&#39;folder&#39;] = folder
        self.__dict__[&#39;status&#39;] = folder.status
        self.__dict__[&#39;dialog&#39;] = folder.dialog
        self.__dict__[&#39;dicm&#39;] = folder.dicm
        self.__dict__[&#39;ds&#39;] = None
        # placeholder DICOM attributes
        # these will populate the dataset and dataframe when data are created
        self.__dict__[&#39;attributes&#39;] = attributes

    @property
    def generation(self):
        return len(self.UID)

    @property
    def key(self):
        &#34;&#34;&#34;The keywords describing the UID of the record&#34;&#34;&#34;

        key = [&#39;PatientID&#39;, &#39;StudyInstanceUID&#39;, &#39;SeriesInstanceUID&#39;, &#39;SOPInstanceUID&#39;]
        return key[0:self.generation]

    def new_uid(self):
        
        return pydicom.uid.generate_uid()

    def data(self):
        &#34;&#34;&#34;Dataframe with current data - excluding those that were removed
        &#34;&#34;&#34;

        # Note: this returns a copy - could be a view instead using .loc?

        if self.folder.path is None:
            return self.folder.dataframe
        current = self.folder.dataframe.removed == False
        data = self.folder.dataframe[current]
        if self.UID == []: 
            return data       
        rows = data[self.key[-1]] == self.UID[-1]
        return data[rows]

    def dataset(self, sortby=None, status=True): 
        &#34;&#34;&#34;Sort instances by a list of attributes.
        
        Args:
            sortby: 
                List of DICOM keywords by which the series is sorted
        Returns:
            An ndarray holding the instances sorted by sortby.
        &#34;&#34;&#34;
        if sortby is None:
            df = self.data()
            return self._dataset_from_df(df)
        else:
            if set(sortby) &lt;= set(self.folder.dataframe):
                df = self.folder.dataframe.loc[self.data().index, sortby]
            else:
                df = utilities.dataframe(self.folder.path, self.files, sortby, self.status)
            df.sort_values(sortby, inplace=True) 
            return self._sorted_dataset_from_df(df, sortby, status=status)

    def _sorted_dataset_from_df(self, df, sortby, status=True): 

        data = []
        vals = df[sortby[0]].unique()
        for i, c in enumerate(vals):
            if status: self.status.progress(i, len(vals), message=&#39;Sorting..&#39;)
            dfc = df[df[sortby[0]] == c]
            if len(sortby) == 1:
                datac = self._dataset_from_df(dfc)
            else:
                datac = self._sorted_dataset_from_df(dfc, sortby[1:], status=False)
            data.append(datac)
        return utilities._stack_arrays(data, align_left=True)

    def _dataset_from_df(self, df): 
        &#34;&#34;&#34;Return datasets as numpy array of object type&#34;&#34;&#34;

        data = np.empty(df.shape[0], dtype=object)
        cnt = 0
        for file, _ in df.iterrows(): # just enumerate over df.index
            #self.status.progress(cnt, df.shape[0])
            data[cnt] = self.folder.instance(file)
            cnt += 1
        #self.status.hide()
        return data

    def array(self, sortby=None, pixels_first=False): 
        &#34;&#34;&#34;Pixel values of the object as an ndarray
        
        Args:
            sortby: 
                Optional list of DICOM keywords by which the volume is sorted
            pixels_first: 
                If True, the (x,y) dimensions are the first dimensions of the array.
                If False, (x,y) are the last dimensions - this is the default.

        Returns:
            An ndarray holding the pixel data.

            An ndarry holding the datasets (instances) of each slice.

        Examples:
            ``` ruby
            # return a 3D array (z,x,y)
            # with the pixel data for each slice
            # in no particular order (z)
            array, _ = series.array()    

            # return a 3D array (x,y,z)   
            # with pixel data in the leading indices                               
            array, _ = series.array(pixels_first = True)    

            # Return a 4D array (x,y,t,k) sorted by acquisition time   
            # The last dimension (k) enumerates all slices with the same acquisition time. 
            # If there is only one image for each acquision time, 
            # the last dimension is a dimension of 1                               
            array, data = series.array(&#39;AcquisitionTime&#39;, pixels_first=True)                         
            v = array[:,:,10,0]                 # First image at the 10th location
            t = data[10,0].AcquisitionTIme      # acquisition time of the same image

            # Return a 4D array (loc, TI, x, y) 
            sortby = [&#39;SliceLocation&#39;,&#39;InversionTime&#39;]
            array, data = series.array(sortby) 
            v = array[10,6,0,:,:]            # First slice at 11th slice location and 7th inversion time    
            Loc = data[10,6,0][sortby[0]]    # Slice location of the same slice
            TI = data[10,6,0][sortby[1]]     # Inversion time of the same slice
            ```  
        &#34;&#34;&#34;
        dataset = self.dataset(sortby)
        array = []
        ds = dataset.ravel()
        for i, im in enumerate(ds):
            self.status.progress(i, len(ds), &#39;Reading pixel data..&#39;)
            if im is None:
                array.append(np.zeros((1,1)))
            else:
                array.append(im.array())
        self.status.hide()
        #array = [im.array() for im in dataset.ravel() if im is not None]
        array = utilities._stack_arrays(array) #db.stack(array)
        array = array.reshape(dataset.shape + array.shape[1:])
        if pixels_first:
            array = np.moveaxis(array, -1, 0)
            array = np.moveaxis(array, -1, 0)
        return array, dataset # REPLACE BY DBARRAY

    def npy(self):

        path = os.path.join(self.folder.path, &#34;dbdicom_npy&#34;)
        if not os.path.isdir(path): os.mkdir(path)
        file = os.path.join(path, self.UID[-1] + &#39;.npy&#39;) 
        return file

    def load_npy(self):

        file = self.npy()
        if not os.path.exists(file):
            return
        with open(file, &#39;rb&#39;) as f:
            array = np.load(f)
        return array

    def save_npy(self, array=None, sortby=None, pixels_first=False):

        if array is None:
            array = self.array(sortby=sortby, pixels_first=pixels_first)
        file = self.npy() 
        with open(file, &#39;wb&#39;) as f:
            np.save(f, array)

    def set_array(self, array, dataset=None, pixels_first=False, inplace=False): 
        &#34;&#34;&#34;
        Set pixel values of a series from a numpy ndarray.

        Since the pixel data do not hold any information about the 
        image such as geometry, or other metainformation,
        a dataset must be provided as well with the same 
        shape as the array except for the slice dimensions. 

        If a dataset is not provided, header info is 
        derived from existing instances in order.

        Args:
            array: 
                numpy ndarray with pixel data.

            dataset: 
                numpy ndarray

                Instances holding the header information. 
                This *must* have the same shape as array, minus the slice dimensions.

            pixels_first: 
                bool

                Specifies whether the pixel dimensions are the first or last dimensions of the series.
                If not provided it is assumed the slice dimensions are the last dimensions
                of the array.

            inplace: 
                bool

                If True (default) the current pixel values in the series 
                are overwritten. If set to False, the new array is added to the series.
        
        Examples:
            ```ruby
            # Invert all images in a series:
            array, _ = series.array()
            series.set_array(-array)

            # Create a maximum intensity projection of the series.
            # Header information for the result is taken from the first image.
            # Results are saved in a new sibling series.
            array, data = series.array()
            array = np.amax(array, axis=0)
            data = np.squeeze(data[0,...])
            series.new_sibling().set_array(array, data)

            # Create a 2D maximum intensity projection along the SliceLocation direction.
            # Header information for the result is taken from the first slice location.
            # Current data of the series are overwritten.
            array, data = series.array(&#39;SliceLocation&#39;)
            array = np.amax(array, axis=0)
            data = np.squeeze(data[0,...])
            series.set_array(array, data)

            # In a series with multiple slice locations and inversion times,
            # replace all images for each slice location with that of the shortest inversion time.
            array, data = series.array([&#39;SliceLocation&#39;,&#39;InversionTime&#39;]) 
            for loc in range(array.shape[0]):               # loop over slice locations
                slice0 = np.squeeze(array[loc,0,0,:,:])     # get the slice with shortest TI 
                TI0 = data[loc,0,0].InversionTime           # get the TI of that slice
                for TI in range(array.shape[1]):            # loop over TIs
                    array[loc,TI,0,:,:] = slice0            # replace each slice with shortest TI
                    data[loc,TI,0].InversionTime = TI0      # replace each TI with shortest TI
            series.set_array(array, data)
            ```
        &#34;&#34;&#34;
        if pixels_first:    # Move to the end (default)
            array = np.moveaxis(array, 0, -1)
            array = np.moveaxis(array, 0, -1)
        if dataset is None:
            dataset = self.dataset()
        # Return with error message if dataset and array do not match.
        nr_of_slices = np.prod(array.shape[:-2])
        if nr_of_slices != np.prod(dataset.shape):
            message = &#39;Error in set_array(): array and dataset do not match&#39;
            message += &#39;\n Array has &#39; + str(nr_of_slices) + &#39; elements&#39;
            message += &#39;\n dataset has &#39; + str(np.prod(dataset.shape)) + &#39; elements&#39;
            message += &#39;\n Check if the keyword pixels_first is set correctly.&#39;
            self.dialog.error(message)
            raise ValueError(message)
        # If self is not a series, create a new series.
        if self.generation != 3:
            series = self.new_series()
        else:
            series = self
        # Reshape, copy instances and save slices.
        array = array.reshape((nr_of_slices, array.shape[-2], array.shape[-1])) # shape (i,x,y)
        dataset = dataset.reshape(nr_of_slices) # shape (i,)

        dataset = db.copy(dataset.tolist(), series, status=self.status)
        for i, instance in enumerate(dataset):
            self.status.progress(i, len(dataset), &#39;Writing array to file..&#39;)
            instance.set_array(array[i,...])
            if inplace: instance.remove() # delete?
           
        #for i, instance in enumerate(dataset):
        #    self.status.progress(i, len(dataset), &#39;Saving data..&#39;)
        #    instance.copy_to(series).set_array(array[i,...])
            # instance.set_array(array[i,...])
        #    if inplace: instance.remove() # delete?

        return series

#    def write_array(self, array, dataset): 
#        &#34;&#34;&#34;
#        Set and array and write it to disk.
#        &#34;&#34;&#34;
#        series = self.set_array(array, dataset)
#        series.write()
#        return series

    @property
    def _SOPClassUID(self):
        &#34;&#34;&#34;The SOP Class UID of the first instance&#34;&#34;&#34;

        data = self.data()
        if data.empty: return None
        return self.data().iloc[0].SOPClassUID

    @property
    def files(self):
        &#34;&#34;&#34;Returns the filepath to the instances in the object.&#34;&#34;&#34;
 
        relpaths = self.data().index.tolist()
        return [os.path.join(self.folder.path, p) for p in relpaths]

    def in_memory(self): # is_in_memory
        &#34;&#34;&#34;Check if the object has been read into memory&#34;&#34;&#34;

        return self.ds is not None

    def on_disk(self): # is_on_disk

        return self.ds is None

    @property
    def parent(self):
        &#34;Returns the parent object&#34;

        return self.dicm.parent(self)
        
    def children(self, index=None, **kwargs):
        &#34;&#34;&#34;List of children&#34;&#34;&#34;

        if self.generation == 4: return []
        if self.in_memory():
            objects = utilities._filter(self.ds, **kwargs)
            if index is not None:
                if index &gt;= len(objects): 
                    return
                else:
                    return objects[index]
            return objects
        return self.records(generation=self.generation+1, index=index, **kwargs)

    def records(self, generation=0, index=None, **kwargs):
        &#34;&#34;&#34;A list of all records of a given generation corresponding to the record.

        If generation is lower then that of the object, 
        all offspring of the given generation are returned.

        If the generation is higher than that of the object,
        the correspondong ancestor is return as a 1-element list.

        Optionally the list can be filtered by index, or by providing a 
        list of DICOM KeyWords and values. In that case only objects
        a returned that fulfill all criteria.
        
        Parameters
        ----------
        generation : int
            The generation to be returned (0 to 4)
        index : int
            Index of the single object to be return
        kwargs : (Key, Value)
            Conditions to filter the objects
        &#34;&#34;&#34;
        objects = []
        if generation == 0:
            obj = self.dicm.object(self.folder, generation=0)
            objects.append(obj)
        else:
            key = self.folder._columns[0:generation]
            data = self.data()
            if data.empty: 
                if index is None:
                    return objects
                else:
                    return
            column = data[key[-1]]
            rec_list = column.unique()
            if index is not None:
                rec_list = [rec_list[index]]
            for rec in rec_list:
                rec_data = data[column == rec]
                row = rec_data.iloc[0]
                obj = self.dicm.object(self.folder, row, generation)
                objects.append(obj)
        objects = utilities._filter(objects, **kwargs)
        if index is not None: return objects[0]
        return objects

    def patients(self, index=None,  **kwargs):
        &#34;&#34;&#34;A list of patients of the object&#34;&#34;&#34;

        if self.generation==4: 
            return self.parent.parent.parent
        if self.generation==3:
            return self.parent.parent
        if self.generation==2:
            self.parent
        if self.generation==1:
            return
        return self.children(index=index, **kwargs)

    def studies(self, index=None, **kwargs):
        &#34;&#34;&#34;A list of studies of the object&#34;&#34;&#34;

        if self.generation==4: 
            return self.parent.parent
        if self.generation==3:
            return self.parent
        if self.generation==2:
            return
        if self.generation==1:
            return self.children(index=index, **kwargs)
        objects = []
        for child in self.children():
            inst = child.studies(**kwargs)
            objects.extend(inst)
        if index is not None:
            if index &gt;= len(objects):
                return
            else:
                return objects[index]
        return objects

    def series(self, index=None, **kwargs):
        &#34;&#34;&#34;A list of series of the object&#34;&#34;&#34;

        if self.generation==4: 
            return self.parent
        if self.generation==3:
            return
        if self.generation==2:
            kids = self.children(index=index, **kwargs)
            return kids
        series = []
        for child in self.children():
            inst = child.series(**kwargs)
            series.extend(inst)
        if index is not None:
            if index &gt;= len(series):
                return
            else:
                return series[index]
        return series

    def instances(self, index=None, **kwargs): # VERY slow - needs optimizing
        &#34;&#34;&#34;A list of instances of the object&#34;&#34;&#34;

        if self.generation==4: 
            return
        if self.generation==3:
            return self.children(index=index, **kwargs)
        instances = []
        for child in self.children():
            inst = child.instances(**kwargs)
            instances.extend(inst)
        if index is not None:
            if index &gt;= len(instances):
                return
            else:
                return instances[index]
        return instances       

    def new_child(self, **attributes):
        &#34;&#34;&#34;Creates a new child object&#34;&#34;&#34;

        obj = self.dicm.new_child(self, **attributes)
        obj.read() # Why??
        return obj

    def new_sibling(self, **attributes):
        &#34;&#34;&#34;
        Creates a new sibling under the same parent.
        &#34;&#34;&#34;
        if self.generation == 0:
            return
        else:
            return self.parent.new_child(**attributes)

    def new_pibling(self, **attributes):
        &#34;&#34;&#34;
        Creates a new sibling of parent.
        &#34;&#34;&#34;
        if self.generation &lt;= 1:
            return
        else:
            return self.parent.new_sibling(**attributes)

    def new_cousin(self, **attributes):
        &#34;&#34;&#34;
        Creates a new sibling of parent.
        &#34;&#34;&#34;
        if self.generation &lt;= 1:
            return
        else:
            return self.new_pibling().new_child(**attributes)

    def new_series(self, **attributes):
        &#34;&#34;&#34;
        Creates a new series under the same parent
        &#34;&#34;&#34; 
        if self.generation &lt;= 1: 
            return self.new_child().new_series(**attributes)
        if self.generation == 2:
            return self.new_child(**attributes)
        if self.generation == 3:
            return self.new_sibling(**attributes)
        if self.generation == 4:
            return self.new_pibling(**attributes) 

    def __getattr__(self, tag):
        &#34;&#34;&#34;Gets the value of the data element with given tag.
        
        Arguments
        ---------
        tag : str
            DICOM KeyWord String

        Returns
        -------
        Value of the corresponding DICOM data element
        &#34;&#34;&#34;
        return self[tag]

    def __setattr__(self, tag, value):
        &#34;&#34;&#34;Sets the value of the data element with given tag.&#34;&#34;&#34;

        if tag == &#39;folder&#39;:
            self.__dict__[&#39;folder&#39;] = value
        elif tag == &#39;ds&#39;:
            self.__dict__[&#39;ds&#39;] = value
        else:
            self[tag] = value

    def __getitem__(self, tags):
        &#34;&#34;&#34;Gets the value of the data elements with specified tags.
        
        Arguments
        ---------
        tags : a string, hexadecimal tuple, or a list of strings and hexadecimal tuples

        Returns
        -------
        A value or a list of values
        &#34;&#34;&#34;
        instance = self.instances(0)
        if instance is not None:
            return instance[tags]

    def __setitem__(self, tags, values):
        &#34;&#34;&#34;Sets the value of the data element with given tag.&#34;&#34;&#34;

        # LAZY - SLOW
        instances = self.instances()
        self.status.message(&#39;Writing DICOM tags..&#39;)
        for i, instance in enumerate(instances):
            instance[tags] = values
            self.status.progress(i, len(instances))
        self.status.hide()

    def remove(self):
        &#34;&#34;&#34;Deletes the object. &#34;&#34;&#34; 

        files = self.files
        if files == []: 
            return
        self.folder.dataframe.loc[self.data().index,&#39;removed&#39;] = True


    def move_to(self, ancestor):
        &#34;&#34;&#34;move object to a new parent.
        
        ancestor:any DICOM Class
            If the object is not a parent, the missing 
            intermediate generations are automatically created.
        &#34;&#34;&#34;
        copy = self.copy_to(ancestor)
        self.remove()
        return copy

#    def move(self, child, ancestor):
#        &#34;&#34;&#34;Move a child object to a new parent&#34;&#34;&#34;

#        if self.in_memory():
#            if child in self.ds:
#                self.ds.remove(child)
#        child = child.move_to(ancestor)
    
    def copy(self):
        &#34;&#34;&#34;Returns a copy in the same parent&#34;&#34;&#34;

        copy = self.copy_to(self.parent)
        if self.in_memory(): copy.read()
        return copy

    def _copy_to_OBSOLETE(self, ancestor, message=None): # functional but slow
        &#34;&#34;&#34;copy object to a new ancestor.
        
        ancestor: Root, Patient or Study
        If the object is not a study, the missing 
        intermediate generations are automatically created.
        &#34;&#34;&#34;
        if self.generation == 0: return
#        if ancestor.generation == 0: return
        copy = self.__class__(self.folder, UID=ancestor.UID)
        if ancestor.in_memory():
            copy.read()
            ancestor.ds.append(copy)
        children = self.children()
        if message is None:
            message = &#34;Copying &#34; + self.__class__.__name__ + &#39; &#39; + self.label()
        self.status.message(message)
        for i, child in enumerate(children):
            child.copy_to(copy)
            self.status.progress(i, len(children))
        self.status.hide()
        return copy

    def _initialize(self, ref=None):

        if self.generation == 4:
            self.ds = utilities.initialize(self.ds, UID=self.UID, ref=ref)
        else:
            for i, obj in enumerate(self.ds):
                if ref is not None:
                    obj._initialize(ref.ds[i])
                else:
                    obj._initialize()

    def merge_with(self, obj, message=None): 

        if self.generation == 0: return
        if message is None:
            message = &#34;Merging &#34; + self.__class__.__name__ + &#39; &#39; + self.label()
        # replace by db.merge()
        return self._merge_with(obj, obj.parent, message=message)

    def copy_to(self, ancestor, message=None):

        if self.generation == 0: return
        if message is None:
            message = &#34;Copying &#34; + self.__class__.__name__ + &#39; &#39; + self.label()
        copy = self.__class__(self.folder, UID=ancestor.UID)
        # replace by db.merge()
        return self._merge_with(copy, ancestor, message=message)

    def _merge_with(self, obj, ancestor, message=None): # obsolete - replace by db.merge()

        if self.in_memory(): # Create the copy in memory
            obj.__dict__[&#39;ds&#39;] = deepcopy(self.ds)
            obj._initialize(self.ds)
            if ancestor.in_memory():
                if ancestor.generation == obj.generation-1:
                    ancestor.ds.append(obj)
            return obj

        # Extend dataframe &amp; create new files
        dfsource = self.data()
        sourcefiles = [os.path.join(self.folder.path, p) for p in dfsource.index.tolist()]
        df = dfsource.copy(deep=True)
        df[&#39;files&#39;] = [self.folder.new_file() for _ in range(df.shape[0])]
        df.set_index(&#39;files&#39;, inplace=True)
        for key in self.folder._columns[self.generation:3]:
            for id in df[key].unique():
                uid = self.folder.new_uid()
                rows = df[key] == id
                df.loc[rows.index, key] = uid
            #    for file in rows.index:
            #        df.at[file, key] = uid
        df.SOPInstanceUID = self.folder.new_uid(df.shape[0])
        df.removed = False
        df.created = True
        copyfiles = df.index.tolist()

        for i, file in enumerate(copyfiles):
            self.status.progress(i, len(copyfiles), message=message)
            df.loc[file, self.folder._columns[0:self.generation]] = obj.UID 
            ds = pydicom.dcmread(sourcefiles[i])
            ds = utilities._initialize(ds, UID=df.loc[file, self.folder._columns[:4]].values.tolist())
            if obj.attributes is not None:
                for key, value in obj.attributes.items():
                    utilities._set_tags(ds, key, value)
                    if key in self.folder._columns[4:]:
                        df.at[file, key] = value  
            ds.save_as(os.path.join(self.folder.path, file))

        self.folder.__dict__[&#39;dataframe&#39;] = pd.concat([self.folder.dataframe, df])
        self.status.hide()

        if ancestor.in_memory():
            if ancestor.generation == obj.generation-1:
                obj.read() # unnecessary read - can be integrated in loop.
                ancestor.ds.append(obj)

        return obj

    def export(self, path):
        &#34;&#34;&#34;Export instances to an external folder.

        The instance itself will not be removed from the DICOM folder.
        Instead a copy of the file will be copied to the external folder.
        
        Arguments
        ---------
        path : str
            path to an external folder. If not provided,
            a window will prompt the user to select one.
        &#34;&#34;&#34;
        instances = self.instances()
        self.status.message(&#39;Exporting..&#39;)
        for i, instance in enumerate(instances):
            instance.export(path)
            self.status.progress(i,len(instances))
        self.status.hide()

    def save_OBSOLETE(self):
        &#34;&#34;&#34;Save all instances of the record.&#34;&#34;&#34;

        # Slow - edit df directly
        self.status.message(&#34;Saving all current instances..&#34;)
        instances = self.instances() 
        for i, instance in enumerate(instances):
            instance.save()
            self.status.progress(i, len(instances))
        self.status.hide()

        self.status.message(&#34;Deleting all removed instances..&#34;)
        if self.__class__.__name__ == &#39;Folder&#39;:
            data = self.folder.dataframe
        else:
            rows = self.folder.dataframe[self.key[-1]] == self.UID[-1]
            data = self.folder.dataframe[rows] 
        removed = data.removed[data.removed]
        files = [os.path.join(self.folder.path, p) for p in removed.index.tolist()]
        for i, file in enumerate(files): 
            os.remove(file)
            self.status.progress(i, len(files))
        self.folder.dataframe.drop(removed.index, inplace=True)
        self.status.hide()

    def save(self, message = &#34;Saving changes..&#34;):
        &#34;&#34;&#34;Save all instances of the record.&#34;&#34;&#34;

        self.status.message(message)
        self.write()
        if self.generation == 0:
            data = self.folder.dataframe
        else:
            rows = self.folder.dataframe[self.key[-1]] == self.UID[-1]
            data = self.folder.dataframe[rows] 

        created = data.created[data.created]   
        removed = data.removed[data.removed]

        files = [os.path.join(self.folder.path, p) for p in removed.index.tolist()]
        for i, file in enumerate(files): 
            self.status.progress(i, len(files), message=&#39;Deleting removed files..&#39;)
            if os.path.exists(file): os.remove(file)
        #self.status.message(&#39;Clearing rapid access storage..&#39;)
        #npyfile = self.npy()
        #if os.path.exists(npyfile): os.remove(npyfile)
        self.status.message(&#39;Done saving..&#39;)
        self.folder.dataframe.loc[created.index, &#39;created&#39;] = False
        self.folder.dataframe.drop(removed.index, inplace=True)

    def restore(self, message = &#34;Restoring saved state..&#34;):
        &#34;&#34;&#34;
        Restore all instances.
        &#34;&#34;&#34;
        self.status.message(message)

        in_memory = self.in_memory() 
        self.clear()

        if self.generation == 0:
            data = self.folder.dataframe
        else:
            rows = self.folder.dataframe[self.key[-1]] == self.UID[-1]
            data = self.folder.dataframe[rows] 
        created = data.created[data.created]   
        removed = data.removed[data.removed]

        files = [os.path.join(self.folder.path, p) for p in created.index.tolist()]
        for i, file in enumerate(files): 
            self.status.progress(i, len(files), message=&#39;Deleting new files..&#39;)
            if os.path.exists(file): os.remove(file)
        self.status.hide()
        self.folder.dataframe.loc[removed.index, &#39;removed&#39;] = False
        self.folder.dataframe.drop(created.index, inplace=True)

        if in_memory: self.read()
        return self
        
    def restore_OBSOLETE(self, message = &#39;Restoring..&#39;):
        &#34;&#34;&#34;
        Restore all instances.
        &#34;&#34;&#34;
        in_memory = self.in_memory() 
        self.clear()

        instances = self.instances()
        self.status.message(message)
        for i, instance in enumerate(instances):
            instance.restore()
            self.status.progress(i,len(instances))
        self.status.hide()

        if in_memory: self.read()
        return self

    def read_dataframe(self, tags):

        return utilities.dataframe(self.folder.path, self.files, tags, self.status)

    def read(self, message = &#39;Reading..&#39;):

        self.status.message(message)
        self.__dict__[&#39;ds&#39;] = self.children()
        for i, child in enumerate(self.ds):
            self.status.progress(i, len(self.ds))
            child.read()
        self.status.hide()

    def write(self):

        if self.ds is None: 
            return
        for i, child in enumerate(self.ds):
            self.status.progress(i, len(self.ds), message=&#39;Writing data..&#39;)
            child.write()
        self.status.hide()

    def clear(self):

        if self.ds is None: 
            return
        for child in self.ds:
            child.clear()
        self.ds = None</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="dbdicom.classes.record.Record"><code class="flex name class">
<span>class <span class="ident">Record</span></span>
<span>(</span><span>folder, UID=[], generation=0, **attributes)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Record():

    def __init__(self, folder, UID=[], generation=0, **attributes):

        objUID = [] + UID
#        for i in range(generation-len(UID)):
        while generation &gt; len(objUID):
            newUID = pydicom.uid.generate_uid()
            objUID.append(newUID)    

        self.__dict__[&#39;UID&#39;] = objUID
        self.__dict__[&#39;folder&#39;] = folder
        self.__dict__[&#39;status&#39;] = folder.status
        self.__dict__[&#39;dialog&#39;] = folder.dialog
        self.__dict__[&#39;dicm&#39;] = folder.dicm
        self.__dict__[&#39;ds&#39;] = None
        # placeholder DICOM attributes
        # these will populate the dataset and dataframe when data are created
        self.__dict__[&#39;attributes&#39;] = attributes

    @property
    def generation(self):
        return len(self.UID)

    @property
    def key(self):
        &#34;&#34;&#34;The keywords describing the UID of the record&#34;&#34;&#34;

        key = [&#39;PatientID&#39;, &#39;StudyInstanceUID&#39;, &#39;SeriesInstanceUID&#39;, &#39;SOPInstanceUID&#39;]
        return key[0:self.generation]

    def new_uid(self):
        
        return pydicom.uid.generate_uid()

    def data(self):
        &#34;&#34;&#34;Dataframe with current data - excluding those that were removed
        &#34;&#34;&#34;

        # Note: this returns a copy - could be a view instead using .loc?

        if self.folder.path is None:
            return self.folder.dataframe
        current = self.folder.dataframe.removed == False
        data = self.folder.dataframe[current]
        if self.UID == []: 
            return data       
        rows = data[self.key[-1]] == self.UID[-1]
        return data[rows]

    def dataset(self, sortby=None, status=True): 
        &#34;&#34;&#34;Sort instances by a list of attributes.
        
        Args:
            sortby: 
                List of DICOM keywords by which the series is sorted
        Returns:
            An ndarray holding the instances sorted by sortby.
        &#34;&#34;&#34;
        if sortby is None:
            df = self.data()
            return self._dataset_from_df(df)
        else:
            if set(sortby) &lt;= set(self.folder.dataframe):
                df = self.folder.dataframe.loc[self.data().index, sortby]
            else:
                df = utilities.dataframe(self.folder.path, self.files, sortby, self.status)
            df.sort_values(sortby, inplace=True) 
            return self._sorted_dataset_from_df(df, sortby, status=status)

    def _sorted_dataset_from_df(self, df, sortby, status=True): 

        data = []
        vals = df[sortby[0]].unique()
        for i, c in enumerate(vals):
            if status: self.status.progress(i, len(vals), message=&#39;Sorting..&#39;)
            dfc = df[df[sortby[0]] == c]
            if len(sortby) == 1:
                datac = self._dataset_from_df(dfc)
            else:
                datac = self._sorted_dataset_from_df(dfc, sortby[1:], status=False)
            data.append(datac)
        return utilities._stack_arrays(data, align_left=True)

    def _dataset_from_df(self, df): 
        &#34;&#34;&#34;Return datasets as numpy array of object type&#34;&#34;&#34;

        data = np.empty(df.shape[0], dtype=object)
        cnt = 0
        for file, _ in df.iterrows(): # just enumerate over df.index
            #self.status.progress(cnt, df.shape[0])
            data[cnt] = self.folder.instance(file)
            cnt += 1
        #self.status.hide()
        return data

    def array(self, sortby=None, pixels_first=False): 
        &#34;&#34;&#34;Pixel values of the object as an ndarray
        
        Args:
            sortby: 
                Optional list of DICOM keywords by which the volume is sorted
            pixels_first: 
                If True, the (x,y) dimensions are the first dimensions of the array.
                If False, (x,y) are the last dimensions - this is the default.

        Returns:
            An ndarray holding the pixel data.

            An ndarry holding the datasets (instances) of each slice.

        Examples:
            ``` ruby
            # return a 3D array (z,x,y)
            # with the pixel data for each slice
            # in no particular order (z)
            array, _ = series.array()    

            # return a 3D array (x,y,z)   
            # with pixel data in the leading indices                               
            array, _ = series.array(pixels_first = True)    

            # Return a 4D array (x,y,t,k) sorted by acquisition time   
            # The last dimension (k) enumerates all slices with the same acquisition time. 
            # If there is only one image for each acquision time, 
            # the last dimension is a dimension of 1                               
            array, data = series.array(&#39;AcquisitionTime&#39;, pixels_first=True)                         
            v = array[:,:,10,0]                 # First image at the 10th location
            t = data[10,0].AcquisitionTIme      # acquisition time of the same image

            # Return a 4D array (loc, TI, x, y) 
            sortby = [&#39;SliceLocation&#39;,&#39;InversionTime&#39;]
            array, data = series.array(sortby) 
            v = array[10,6,0,:,:]            # First slice at 11th slice location and 7th inversion time    
            Loc = data[10,6,0][sortby[0]]    # Slice location of the same slice
            TI = data[10,6,0][sortby[1]]     # Inversion time of the same slice
            ```  
        &#34;&#34;&#34;
        dataset = self.dataset(sortby)
        array = []
        ds = dataset.ravel()
        for i, im in enumerate(ds):
            self.status.progress(i, len(ds), &#39;Reading pixel data..&#39;)
            if im is None:
                array.append(np.zeros((1,1)))
            else:
                array.append(im.array())
        self.status.hide()
        #array = [im.array() for im in dataset.ravel() if im is not None]
        array = utilities._stack_arrays(array) #db.stack(array)
        array = array.reshape(dataset.shape + array.shape[1:])
        if pixels_first:
            array = np.moveaxis(array, -1, 0)
            array = np.moveaxis(array, -1, 0)
        return array, dataset # REPLACE BY DBARRAY

    def npy(self):

        path = os.path.join(self.folder.path, &#34;dbdicom_npy&#34;)
        if not os.path.isdir(path): os.mkdir(path)
        file = os.path.join(path, self.UID[-1] + &#39;.npy&#39;) 
        return file

    def load_npy(self):

        file = self.npy()
        if not os.path.exists(file):
            return
        with open(file, &#39;rb&#39;) as f:
            array = np.load(f)
        return array

    def save_npy(self, array=None, sortby=None, pixels_first=False):

        if array is None:
            array = self.array(sortby=sortby, pixels_first=pixels_first)
        file = self.npy() 
        with open(file, &#39;wb&#39;) as f:
            np.save(f, array)

    def set_array(self, array, dataset=None, pixels_first=False, inplace=False): 
        &#34;&#34;&#34;
        Set pixel values of a series from a numpy ndarray.

        Since the pixel data do not hold any information about the 
        image such as geometry, or other metainformation,
        a dataset must be provided as well with the same 
        shape as the array except for the slice dimensions. 

        If a dataset is not provided, header info is 
        derived from existing instances in order.

        Args:
            array: 
                numpy ndarray with pixel data.

            dataset: 
                numpy ndarray

                Instances holding the header information. 
                This *must* have the same shape as array, minus the slice dimensions.

            pixels_first: 
                bool

                Specifies whether the pixel dimensions are the first or last dimensions of the series.
                If not provided it is assumed the slice dimensions are the last dimensions
                of the array.

            inplace: 
                bool

                If True (default) the current pixel values in the series 
                are overwritten. If set to False, the new array is added to the series.
        
        Examples:
            ```ruby
            # Invert all images in a series:
            array, _ = series.array()
            series.set_array(-array)

            # Create a maximum intensity projection of the series.
            # Header information for the result is taken from the first image.
            # Results are saved in a new sibling series.
            array, data = series.array()
            array = np.amax(array, axis=0)
            data = np.squeeze(data[0,...])
            series.new_sibling().set_array(array, data)

            # Create a 2D maximum intensity projection along the SliceLocation direction.
            # Header information for the result is taken from the first slice location.
            # Current data of the series are overwritten.
            array, data = series.array(&#39;SliceLocation&#39;)
            array = np.amax(array, axis=0)
            data = np.squeeze(data[0,...])
            series.set_array(array, data)

            # In a series with multiple slice locations and inversion times,
            # replace all images for each slice location with that of the shortest inversion time.
            array, data = series.array([&#39;SliceLocation&#39;,&#39;InversionTime&#39;]) 
            for loc in range(array.shape[0]):               # loop over slice locations
                slice0 = np.squeeze(array[loc,0,0,:,:])     # get the slice with shortest TI 
                TI0 = data[loc,0,0].InversionTime           # get the TI of that slice
                for TI in range(array.shape[1]):            # loop over TIs
                    array[loc,TI,0,:,:] = slice0            # replace each slice with shortest TI
                    data[loc,TI,0].InversionTime = TI0      # replace each TI with shortest TI
            series.set_array(array, data)
            ```
        &#34;&#34;&#34;
        if pixels_first:    # Move to the end (default)
            array = np.moveaxis(array, 0, -1)
            array = np.moveaxis(array, 0, -1)
        if dataset is None:
            dataset = self.dataset()
        # Return with error message if dataset and array do not match.
        nr_of_slices = np.prod(array.shape[:-2])
        if nr_of_slices != np.prod(dataset.shape):
            message = &#39;Error in set_array(): array and dataset do not match&#39;
            message += &#39;\n Array has &#39; + str(nr_of_slices) + &#39; elements&#39;
            message += &#39;\n dataset has &#39; + str(np.prod(dataset.shape)) + &#39; elements&#39;
            message += &#39;\n Check if the keyword pixels_first is set correctly.&#39;
            self.dialog.error(message)
            raise ValueError(message)
        # If self is not a series, create a new series.
        if self.generation != 3:
            series = self.new_series()
        else:
            series = self
        # Reshape, copy instances and save slices.
        array = array.reshape((nr_of_slices, array.shape[-2], array.shape[-1])) # shape (i,x,y)
        dataset = dataset.reshape(nr_of_slices) # shape (i,)

        dataset = db.copy(dataset.tolist(), series, status=self.status)
        for i, instance in enumerate(dataset):
            self.status.progress(i, len(dataset), &#39;Writing array to file..&#39;)
            instance.set_array(array[i,...])
            if inplace: instance.remove() # delete?
           
        #for i, instance in enumerate(dataset):
        #    self.status.progress(i, len(dataset), &#39;Saving data..&#39;)
        #    instance.copy_to(series).set_array(array[i,...])
            # instance.set_array(array[i,...])
        #    if inplace: instance.remove() # delete?

        return series

#    def write_array(self, array, dataset): 
#        &#34;&#34;&#34;
#        Set and array and write it to disk.
#        &#34;&#34;&#34;
#        series = self.set_array(array, dataset)
#        series.write()
#        return series

    @property
    def _SOPClassUID(self):
        &#34;&#34;&#34;The SOP Class UID of the first instance&#34;&#34;&#34;

        data = self.data()
        if data.empty: return None
        return self.data().iloc[0].SOPClassUID

    @property
    def files(self):
        &#34;&#34;&#34;Returns the filepath to the instances in the object.&#34;&#34;&#34;
 
        relpaths = self.data().index.tolist()
        return [os.path.join(self.folder.path, p) for p in relpaths]

    def in_memory(self): # is_in_memory
        &#34;&#34;&#34;Check if the object has been read into memory&#34;&#34;&#34;

        return self.ds is not None

    def on_disk(self): # is_on_disk

        return self.ds is None

    @property
    def parent(self):
        &#34;Returns the parent object&#34;

        return self.dicm.parent(self)
        
    def children(self, index=None, **kwargs):
        &#34;&#34;&#34;List of children&#34;&#34;&#34;

        if self.generation == 4: return []
        if self.in_memory():
            objects = utilities._filter(self.ds, **kwargs)
            if index is not None:
                if index &gt;= len(objects): 
                    return
                else:
                    return objects[index]
            return objects
        return self.records(generation=self.generation+1, index=index, **kwargs)

    def records(self, generation=0, index=None, **kwargs):
        &#34;&#34;&#34;A list of all records of a given generation corresponding to the record.

        If generation is lower then that of the object, 
        all offspring of the given generation are returned.

        If the generation is higher than that of the object,
        the correspondong ancestor is return as a 1-element list.

        Optionally the list can be filtered by index, or by providing a 
        list of DICOM KeyWords and values. In that case only objects
        a returned that fulfill all criteria.
        
        Parameters
        ----------
        generation : int
            The generation to be returned (0 to 4)
        index : int
            Index of the single object to be return
        kwargs : (Key, Value)
            Conditions to filter the objects
        &#34;&#34;&#34;
        objects = []
        if generation == 0:
            obj = self.dicm.object(self.folder, generation=0)
            objects.append(obj)
        else:
            key = self.folder._columns[0:generation]
            data = self.data()
            if data.empty: 
                if index is None:
                    return objects
                else:
                    return
            column = data[key[-1]]
            rec_list = column.unique()
            if index is not None:
                rec_list = [rec_list[index]]
            for rec in rec_list:
                rec_data = data[column == rec]
                row = rec_data.iloc[0]
                obj = self.dicm.object(self.folder, row, generation)
                objects.append(obj)
        objects = utilities._filter(objects, **kwargs)
        if index is not None: return objects[0]
        return objects

    def patients(self, index=None,  **kwargs):
        &#34;&#34;&#34;A list of patients of the object&#34;&#34;&#34;

        if self.generation==4: 
            return self.parent.parent.parent
        if self.generation==3:
            return self.parent.parent
        if self.generation==2:
            self.parent
        if self.generation==1:
            return
        return self.children(index=index, **kwargs)

    def studies(self, index=None, **kwargs):
        &#34;&#34;&#34;A list of studies of the object&#34;&#34;&#34;

        if self.generation==4: 
            return self.parent.parent
        if self.generation==3:
            return self.parent
        if self.generation==2:
            return
        if self.generation==1:
            return self.children(index=index, **kwargs)
        objects = []
        for child in self.children():
            inst = child.studies(**kwargs)
            objects.extend(inst)
        if index is not None:
            if index &gt;= len(objects):
                return
            else:
                return objects[index]
        return objects

    def series(self, index=None, **kwargs):
        &#34;&#34;&#34;A list of series of the object&#34;&#34;&#34;

        if self.generation==4: 
            return self.parent
        if self.generation==3:
            return
        if self.generation==2:
            kids = self.children(index=index, **kwargs)
            return kids
        series = []
        for child in self.children():
            inst = child.series(**kwargs)
            series.extend(inst)
        if index is not None:
            if index &gt;= len(series):
                return
            else:
                return series[index]
        return series

    def instances(self, index=None, **kwargs): # VERY slow - needs optimizing
        &#34;&#34;&#34;A list of instances of the object&#34;&#34;&#34;

        if self.generation==4: 
            return
        if self.generation==3:
            return self.children(index=index, **kwargs)
        instances = []
        for child in self.children():
            inst = child.instances(**kwargs)
            instances.extend(inst)
        if index is not None:
            if index &gt;= len(instances):
                return
            else:
                return instances[index]
        return instances       

    def new_child(self, **attributes):
        &#34;&#34;&#34;Creates a new child object&#34;&#34;&#34;

        obj = self.dicm.new_child(self, **attributes)
        obj.read() # Why??
        return obj

    def new_sibling(self, **attributes):
        &#34;&#34;&#34;
        Creates a new sibling under the same parent.
        &#34;&#34;&#34;
        if self.generation == 0:
            return
        else:
            return self.parent.new_child(**attributes)

    def new_pibling(self, **attributes):
        &#34;&#34;&#34;
        Creates a new sibling of parent.
        &#34;&#34;&#34;
        if self.generation &lt;= 1:
            return
        else:
            return self.parent.new_sibling(**attributes)

    def new_cousin(self, **attributes):
        &#34;&#34;&#34;
        Creates a new sibling of parent.
        &#34;&#34;&#34;
        if self.generation &lt;= 1:
            return
        else:
            return self.new_pibling().new_child(**attributes)

    def new_series(self, **attributes):
        &#34;&#34;&#34;
        Creates a new series under the same parent
        &#34;&#34;&#34; 
        if self.generation &lt;= 1: 
            return self.new_child().new_series(**attributes)
        if self.generation == 2:
            return self.new_child(**attributes)
        if self.generation == 3:
            return self.new_sibling(**attributes)
        if self.generation == 4:
            return self.new_pibling(**attributes) 

    def __getattr__(self, tag):
        &#34;&#34;&#34;Gets the value of the data element with given tag.
        
        Arguments
        ---------
        tag : str
            DICOM KeyWord String

        Returns
        -------
        Value of the corresponding DICOM data element
        &#34;&#34;&#34;
        return self[tag]

    def __setattr__(self, tag, value):
        &#34;&#34;&#34;Sets the value of the data element with given tag.&#34;&#34;&#34;

        if tag == &#39;folder&#39;:
            self.__dict__[&#39;folder&#39;] = value
        elif tag == &#39;ds&#39;:
            self.__dict__[&#39;ds&#39;] = value
        else:
            self[tag] = value

    def __getitem__(self, tags):
        &#34;&#34;&#34;Gets the value of the data elements with specified tags.
        
        Arguments
        ---------
        tags : a string, hexadecimal tuple, or a list of strings and hexadecimal tuples

        Returns
        -------
        A value or a list of values
        &#34;&#34;&#34;
        instance = self.instances(0)
        if instance is not None:
            return instance[tags]

    def __setitem__(self, tags, values):
        &#34;&#34;&#34;Sets the value of the data element with given tag.&#34;&#34;&#34;

        # LAZY - SLOW
        instances = self.instances()
        self.status.message(&#39;Writing DICOM tags..&#39;)
        for i, instance in enumerate(instances):
            instance[tags] = values
            self.status.progress(i, len(instances))
        self.status.hide()

    def remove(self):
        &#34;&#34;&#34;Deletes the object. &#34;&#34;&#34; 

        files = self.files
        if files == []: 
            return
        self.folder.dataframe.loc[self.data().index,&#39;removed&#39;] = True


    def move_to(self, ancestor):
        &#34;&#34;&#34;move object to a new parent.
        
        ancestor:any DICOM Class
            If the object is not a parent, the missing 
            intermediate generations are automatically created.
        &#34;&#34;&#34;
        copy = self.copy_to(ancestor)
        self.remove()
        return copy

#    def move(self, child, ancestor):
#        &#34;&#34;&#34;Move a child object to a new parent&#34;&#34;&#34;

#        if self.in_memory():
#            if child in self.ds:
#                self.ds.remove(child)
#        child = child.move_to(ancestor)
    
    def copy(self):
        &#34;&#34;&#34;Returns a copy in the same parent&#34;&#34;&#34;

        copy = self.copy_to(self.parent)
        if self.in_memory(): copy.read()
        return copy

    def _copy_to_OBSOLETE(self, ancestor, message=None): # functional but slow
        &#34;&#34;&#34;copy object to a new ancestor.
        
        ancestor: Root, Patient or Study
        If the object is not a study, the missing 
        intermediate generations are automatically created.
        &#34;&#34;&#34;
        if self.generation == 0: return
#        if ancestor.generation == 0: return
        copy = self.__class__(self.folder, UID=ancestor.UID)
        if ancestor.in_memory():
            copy.read()
            ancestor.ds.append(copy)
        children = self.children()
        if message is None:
            message = &#34;Copying &#34; + self.__class__.__name__ + &#39; &#39; + self.label()
        self.status.message(message)
        for i, child in enumerate(children):
            child.copy_to(copy)
            self.status.progress(i, len(children))
        self.status.hide()
        return copy

    def _initialize(self, ref=None):

        if self.generation == 4:
            self.ds = utilities.initialize(self.ds, UID=self.UID, ref=ref)
        else:
            for i, obj in enumerate(self.ds):
                if ref is not None:
                    obj._initialize(ref.ds[i])
                else:
                    obj._initialize()

    def merge_with(self, obj, message=None): 

        if self.generation == 0: return
        if message is None:
            message = &#34;Merging &#34; + self.__class__.__name__ + &#39; &#39; + self.label()
        # replace by db.merge()
        return self._merge_with(obj, obj.parent, message=message)

    def copy_to(self, ancestor, message=None):

        if self.generation == 0: return
        if message is None:
            message = &#34;Copying &#34; + self.__class__.__name__ + &#39; &#39; + self.label()
        copy = self.__class__(self.folder, UID=ancestor.UID)
        # replace by db.merge()
        return self._merge_with(copy, ancestor, message=message)

    def _merge_with(self, obj, ancestor, message=None): # obsolete - replace by db.merge()

        if self.in_memory(): # Create the copy in memory
            obj.__dict__[&#39;ds&#39;] = deepcopy(self.ds)
            obj._initialize(self.ds)
            if ancestor.in_memory():
                if ancestor.generation == obj.generation-1:
                    ancestor.ds.append(obj)
            return obj

        # Extend dataframe &amp; create new files
        dfsource = self.data()
        sourcefiles = [os.path.join(self.folder.path, p) for p in dfsource.index.tolist()]
        df = dfsource.copy(deep=True)
        df[&#39;files&#39;] = [self.folder.new_file() for _ in range(df.shape[0])]
        df.set_index(&#39;files&#39;, inplace=True)
        for key in self.folder._columns[self.generation:3]:
            for id in df[key].unique():
                uid = self.folder.new_uid()
                rows = df[key] == id
                df.loc[rows.index, key] = uid
            #    for file in rows.index:
            #        df.at[file, key] = uid
        df.SOPInstanceUID = self.folder.new_uid(df.shape[0])
        df.removed = False
        df.created = True
        copyfiles = df.index.tolist()

        for i, file in enumerate(copyfiles):
            self.status.progress(i, len(copyfiles), message=message)
            df.loc[file, self.folder._columns[0:self.generation]] = obj.UID 
            ds = pydicom.dcmread(sourcefiles[i])
            ds = utilities._initialize(ds, UID=df.loc[file, self.folder._columns[:4]].values.tolist())
            if obj.attributes is not None:
                for key, value in obj.attributes.items():
                    utilities._set_tags(ds, key, value)
                    if key in self.folder._columns[4:]:
                        df.at[file, key] = value  
            ds.save_as(os.path.join(self.folder.path, file))

        self.folder.__dict__[&#39;dataframe&#39;] = pd.concat([self.folder.dataframe, df])
        self.status.hide()

        if ancestor.in_memory():
            if ancestor.generation == obj.generation-1:
                obj.read() # unnecessary read - can be integrated in loop.
                ancestor.ds.append(obj)

        return obj

    def export(self, path):
        &#34;&#34;&#34;Export instances to an external folder.

        The instance itself will not be removed from the DICOM folder.
        Instead a copy of the file will be copied to the external folder.
        
        Arguments
        ---------
        path : str
            path to an external folder. If not provided,
            a window will prompt the user to select one.
        &#34;&#34;&#34;
        instances = self.instances()
        self.status.message(&#39;Exporting..&#39;)
        for i, instance in enumerate(instances):
            instance.export(path)
            self.status.progress(i,len(instances))
        self.status.hide()

    def save_OBSOLETE(self):
        &#34;&#34;&#34;Save all instances of the record.&#34;&#34;&#34;

        # Slow - edit df directly
        self.status.message(&#34;Saving all current instances..&#34;)
        instances = self.instances() 
        for i, instance in enumerate(instances):
            instance.save()
            self.status.progress(i, len(instances))
        self.status.hide()

        self.status.message(&#34;Deleting all removed instances..&#34;)
        if self.__class__.__name__ == &#39;Folder&#39;:
            data = self.folder.dataframe
        else:
            rows = self.folder.dataframe[self.key[-1]] == self.UID[-1]
            data = self.folder.dataframe[rows] 
        removed = data.removed[data.removed]
        files = [os.path.join(self.folder.path, p) for p in removed.index.tolist()]
        for i, file in enumerate(files): 
            os.remove(file)
            self.status.progress(i, len(files))
        self.folder.dataframe.drop(removed.index, inplace=True)
        self.status.hide()

    def save(self, message = &#34;Saving changes..&#34;):
        &#34;&#34;&#34;Save all instances of the record.&#34;&#34;&#34;

        self.status.message(message)
        self.write()
        if self.generation == 0:
            data = self.folder.dataframe
        else:
            rows = self.folder.dataframe[self.key[-1]] == self.UID[-1]
            data = self.folder.dataframe[rows] 

        created = data.created[data.created]   
        removed = data.removed[data.removed]

        files = [os.path.join(self.folder.path, p) for p in removed.index.tolist()]
        for i, file in enumerate(files): 
            self.status.progress(i, len(files), message=&#39;Deleting removed files..&#39;)
            if os.path.exists(file): os.remove(file)
        #self.status.message(&#39;Clearing rapid access storage..&#39;)
        #npyfile = self.npy()
        #if os.path.exists(npyfile): os.remove(npyfile)
        self.status.message(&#39;Done saving..&#39;)
        self.folder.dataframe.loc[created.index, &#39;created&#39;] = False
        self.folder.dataframe.drop(removed.index, inplace=True)

    def restore(self, message = &#34;Restoring saved state..&#34;):
        &#34;&#34;&#34;
        Restore all instances.
        &#34;&#34;&#34;
        self.status.message(message)

        in_memory = self.in_memory() 
        self.clear()

        if self.generation == 0:
            data = self.folder.dataframe
        else:
            rows = self.folder.dataframe[self.key[-1]] == self.UID[-1]
            data = self.folder.dataframe[rows] 
        created = data.created[data.created]   
        removed = data.removed[data.removed]

        files = [os.path.join(self.folder.path, p) for p in created.index.tolist()]
        for i, file in enumerate(files): 
            self.status.progress(i, len(files), message=&#39;Deleting new files..&#39;)
            if os.path.exists(file): os.remove(file)
        self.status.hide()
        self.folder.dataframe.loc[removed.index, &#39;removed&#39;] = False
        self.folder.dataframe.drop(created.index, inplace=True)

        if in_memory: self.read()
        return self
        
    def restore_OBSOLETE(self, message = &#39;Restoring..&#39;):
        &#34;&#34;&#34;
        Restore all instances.
        &#34;&#34;&#34;
        in_memory = self.in_memory() 
        self.clear()

        instances = self.instances()
        self.status.message(message)
        for i, instance in enumerate(instances):
            instance.restore()
            self.status.progress(i,len(instances))
        self.status.hide()

        if in_memory: self.read()
        return self

    def read_dataframe(self, tags):

        return utilities.dataframe(self.folder.path, self.files, tags, self.status)

    def read(self, message = &#39;Reading..&#39;):

        self.status.message(message)
        self.__dict__[&#39;ds&#39;] = self.children()
        for i, child in enumerate(self.ds):
            self.status.progress(i, len(self.ds))
            child.read()
        self.status.hide()

    def write(self):

        if self.ds is None: 
            return
        for i, child in enumerate(self.ds):
            self.status.progress(i, len(self.ds), message=&#39;Writing data..&#39;)
            child.write()
        self.status.hide()

    def clear(self):

        if self.ds is None: 
            return
        for child in self.ds:
            child.clear()
        self.ds = None</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="dbdicom.classes.database.Database" href="database.html#dbdicom.classes.database.Database">Database</a></li>
<li><a title="dbdicom.classes.instance.Instance" href="instance.html#dbdicom.classes.instance.Instance">Instance</a></li>
<li><a title="dbdicom.classes.patient.Patient" href="patient.html#dbdicom.classes.patient.Patient">Patient</a></li>
<li><a title="dbdicom.classes.series.Series" href="series.html#dbdicom.classes.series.Series">Series</a></li>
<li><a title="dbdicom.classes.study.Study" href="study.html#dbdicom.classes.study.Study">Study</a></li>
</ul>
<h3>Instance variables</h3>
<dl>
<dt id="dbdicom.classes.record.Record.generation"><code class="name">var <span class="ident">generation</span></code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def generation(self):
    return len(self.UID)</code></pre>
</details>
</dd>
<dt id="dbdicom.classes.record.Record.key"><code class="name">var <span class="ident">key</span></code></dt>
<dd>
<div class="desc"><p>The keywords describing the UID of the record</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def key(self):
    &#34;&#34;&#34;The keywords describing the UID of the record&#34;&#34;&#34;

    key = [&#39;PatientID&#39;, &#39;StudyInstanceUID&#39;, &#39;SeriesInstanceUID&#39;, &#39;SOPInstanceUID&#39;]
    return key[0:self.generation]</code></pre>
</details>
</dd>
<dt id="dbdicom.classes.record.Record.files"><code class="name">var <span class="ident">files</span></code></dt>
<dd>
<div class="desc"><p>Returns the filepath to the instances in the object.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def files(self):
    &#34;&#34;&#34;Returns the filepath to the instances in the object.&#34;&#34;&#34;

    relpaths = self.data().index.tolist()
    return [os.path.join(self.folder.path, p) for p in relpaths]</code></pre>
</details>
</dd>
<dt id="dbdicom.classes.record.Record.parent"><code class="name">var <span class="ident">parent</span></code></dt>
<dd>
<div class="desc"><p>Returns the parent object</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def parent(self):
    &#34;Returns the parent object&#34;

    return self.dicm.parent(self)</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="dbdicom.classes.record.Record.new_uid"><code class="name flex">
<span>def <span class="ident">new_uid</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def new_uid(self):
    
    return pydicom.uid.generate_uid()</code></pre>
</details>
</dd>
<dt id="dbdicom.classes.record.Record.data"><code class="name flex">
<span>def <span class="ident">data</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Dataframe with current data - excluding those that were removed</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def data(self):
    &#34;&#34;&#34;Dataframe with current data - excluding those that were removed
    &#34;&#34;&#34;

    # Note: this returns a copy - could be a view instead using .loc?

    if self.folder.path is None:
        return self.folder.dataframe
    current = self.folder.dataframe.removed == False
    data = self.folder.dataframe[current]
    if self.UID == []: 
        return data       
    rows = data[self.key[-1]] == self.UID[-1]
    return data[rows]</code></pre>
</details>
</dd>
<dt id="dbdicom.classes.record.Record.dataset"><code class="name flex">
<span>def <span class="ident">dataset</span></span>(<span>self, sortby=None, status=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Sort instances by a list of attributes.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>sortby</code></strong></dt>
<dd>List of DICOM keywords by which the series is sorted</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>An ndarray holding the instances sorted by sortby.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def dataset(self, sortby=None, status=True): 
    &#34;&#34;&#34;Sort instances by a list of attributes.
    
    Args:
        sortby: 
            List of DICOM keywords by which the series is sorted
    Returns:
        An ndarray holding the instances sorted by sortby.
    &#34;&#34;&#34;
    if sortby is None:
        df = self.data()
        return self._dataset_from_df(df)
    else:
        if set(sortby) &lt;= set(self.folder.dataframe):
            df = self.folder.dataframe.loc[self.data().index, sortby]
        else:
            df = utilities.dataframe(self.folder.path, self.files, sortby, self.status)
        df.sort_values(sortby, inplace=True) 
        return self._sorted_dataset_from_df(df, sortby, status=status)</code></pre>
</details>
</dd>
<dt id="dbdicom.classes.record.Record.array"><code class="name flex">
<span>def <span class="ident">array</span></span>(<span>self, sortby=None, pixels_first=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Pixel values of the object as an ndarray</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>sortby</code></strong></dt>
<dd>Optional list of DICOM keywords by which the volume is sorted</dd>
<dt><strong><code>pixels_first</code></strong></dt>
<dd>If True, the (x,y) dimensions are the first dimensions of the array.
If False, (x,y) are the last dimensions - this is the default.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>An ndarray holding the pixel data.</p>
<p>An ndarry holding the datasets (instances) of each slice.</p>
<h2 id="examples">Examples</h2>
<pre><code class="language-ruby"># return a 3D array (z,x,y)
# with the pixel data for each slice
# in no particular order (z)
array, _ = series.array()    

# return a 3D array (x,y,z)   
# with pixel data in the leading indices                               
array, _ = series.array(pixels_first = True)    

# Return a 4D array (x,y,t,k) sorted by acquisition time   
# The last dimension (k) enumerates all slices with the same acquisition time. 
# If there is only one image for each acquision time, 
# the last dimension is a dimension of 1                               
array, data = series.array('AcquisitionTime', pixels_first=True)                         
v = array[:,:,10,0]                 # First image at the 10th location
t = data[10,0].AcquisitionTIme      # acquisition time of the same image

# Return a 4D array (loc, TI, x, y) 
sortby = ['SliceLocation','InversionTime']
array, data = series.array(sortby) 
v = array[10,6,0,:,:]            # First slice at 11th slice location and 7th inversion time    
Loc = data[10,6,0][sortby[0]]    # Slice location of the same slice
TI = data[10,6,0][sortby[1]]     # Inversion time of the same slice
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def array(self, sortby=None, pixels_first=False): 
    &#34;&#34;&#34;Pixel values of the object as an ndarray
    
    Args:
        sortby: 
            Optional list of DICOM keywords by which the volume is sorted
        pixels_first: 
            If True, the (x,y) dimensions are the first dimensions of the array.
            If False, (x,y) are the last dimensions - this is the default.

    Returns:
        An ndarray holding the pixel data.

        An ndarry holding the datasets (instances) of each slice.

    Examples:
        ``` ruby
        # return a 3D array (z,x,y)
        # with the pixel data for each slice
        # in no particular order (z)
        array, _ = series.array()    

        # return a 3D array (x,y,z)   
        # with pixel data in the leading indices                               
        array, _ = series.array(pixels_first = True)    

        # Return a 4D array (x,y,t,k) sorted by acquisition time   
        # The last dimension (k) enumerates all slices with the same acquisition time. 
        # If there is only one image for each acquision time, 
        # the last dimension is a dimension of 1                               
        array, data = series.array(&#39;AcquisitionTime&#39;, pixels_first=True)                         
        v = array[:,:,10,0]                 # First image at the 10th location
        t = data[10,0].AcquisitionTIme      # acquisition time of the same image

        # Return a 4D array (loc, TI, x, y) 
        sortby = [&#39;SliceLocation&#39;,&#39;InversionTime&#39;]
        array, data = series.array(sortby) 
        v = array[10,6,0,:,:]            # First slice at 11th slice location and 7th inversion time    
        Loc = data[10,6,0][sortby[0]]    # Slice location of the same slice
        TI = data[10,6,0][sortby[1]]     # Inversion time of the same slice
        ```  
    &#34;&#34;&#34;
    dataset = self.dataset(sortby)
    array = []
    ds = dataset.ravel()
    for i, im in enumerate(ds):
        self.status.progress(i, len(ds), &#39;Reading pixel data..&#39;)
        if im is None:
            array.append(np.zeros((1,1)))
        else:
            array.append(im.array())
    self.status.hide()
    #array = [im.array() for im in dataset.ravel() if im is not None]
    array = utilities._stack_arrays(array) #db.stack(array)
    array = array.reshape(dataset.shape + array.shape[1:])
    if pixels_first:
        array = np.moveaxis(array, -1, 0)
        array = np.moveaxis(array, -1, 0)
    return array, dataset # REPLACE BY DBARRAY</code></pre>
</details>
</dd>
<dt id="dbdicom.classes.record.Record.npy"><code class="name flex">
<span>def <span class="ident">npy</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def npy(self):

    path = os.path.join(self.folder.path, &#34;dbdicom_npy&#34;)
    if not os.path.isdir(path): os.mkdir(path)
    file = os.path.join(path, self.UID[-1] + &#39;.npy&#39;) 
    return file</code></pre>
</details>
</dd>
<dt id="dbdicom.classes.record.Record.load_npy"><code class="name flex">
<span>def <span class="ident">load_npy</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_npy(self):

    file = self.npy()
    if not os.path.exists(file):
        return
    with open(file, &#39;rb&#39;) as f:
        array = np.load(f)
    return array</code></pre>
</details>
</dd>
<dt id="dbdicom.classes.record.Record.save_npy"><code class="name flex">
<span>def <span class="ident">save_npy</span></span>(<span>self, array=None, sortby=None, pixels_first=False)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_npy(self, array=None, sortby=None, pixels_first=False):

    if array is None:
        array = self.array(sortby=sortby, pixels_first=pixels_first)
    file = self.npy() 
    with open(file, &#39;wb&#39;) as f:
        np.save(f, array)</code></pre>
</details>
</dd>
<dt id="dbdicom.classes.record.Record.set_array"><code class="name flex">
<span>def <span class="ident">set_array</span></span>(<span>self, array, dataset=None, pixels_first=False, inplace=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Set pixel values of a series from a numpy ndarray.</p>
<p>Since the pixel data do not hold any information about the
image such as geometry, or other metainformation,
a dataset must be provided as well with the same
shape as the array except for the slice dimensions. </p>
<p>If a dataset is not provided, header info is
derived from existing instances in order.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>array</code></strong></dt>
<dd>numpy ndarray with pixel data.</dd>
<dt><strong><code>dataset</code></strong></dt>
<dd>
<p>numpy ndarray</p>
<p>Instances holding the header information.
This <em>must</em> have the same shape as array, minus the slice dimensions.</p>
</dd>
<dt><strong><code>pixels_first</code></strong></dt>
<dd>
<p>bool</p>
<p>Specifies whether the pixel dimensions are the first or last dimensions of the series.
If not provided it is assumed the slice dimensions are the last dimensions
of the array.</p>
</dd>
<dt><strong><code>inplace</code></strong></dt>
<dd>
<p>bool</p>
<p>If True (default) the current pixel values in the series
are overwritten. If set to False, the new array is added to the series.</p>
</dd>
</dl>
<h2 id="examples">Examples</h2>
<pre><code class="language-ruby"># Invert all images in a series:
array, _ = series.array()
series.set_array(-array)

# Create a maximum intensity projection of the series.
# Header information for the result is taken from the first image.
# Results are saved in a new sibling series.
array, data = series.array()
array = np.amax(array, axis=0)
data = np.squeeze(data[0,...])
series.new_sibling().set_array(array, data)

# Create a 2D maximum intensity projection along the SliceLocation direction.
# Header information for the result is taken from the first slice location.
# Current data of the series are overwritten.
array, data = series.array('SliceLocation')
array = np.amax(array, axis=0)
data = np.squeeze(data[0,...])
series.set_array(array, data)

# In a series with multiple slice locations and inversion times,
# replace all images for each slice location with that of the shortest inversion time.
array, data = series.array(['SliceLocation','InversionTime']) 
for loc in range(array.shape[0]):               # loop over slice locations
    slice0 = np.squeeze(array[loc,0,0,:,:])     # get the slice with shortest TI 
    TI0 = data[loc,0,0].InversionTime           # get the TI of that slice
    for TI in range(array.shape[1]):            # loop over TIs
        array[loc,TI,0,:,:] = slice0            # replace each slice with shortest TI
        data[loc,TI,0].InversionTime = TI0      # replace each TI with shortest TI
series.set_array(array, data)
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_array(self, array, dataset=None, pixels_first=False, inplace=False): 
    &#34;&#34;&#34;
    Set pixel values of a series from a numpy ndarray.

    Since the pixel data do not hold any information about the 
    image such as geometry, or other metainformation,
    a dataset must be provided as well with the same 
    shape as the array except for the slice dimensions. 

    If a dataset is not provided, header info is 
    derived from existing instances in order.

    Args:
        array: 
            numpy ndarray with pixel data.

        dataset: 
            numpy ndarray

            Instances holding the header information. 
            This *must* have the same shape as array, minus the slice dimensions.

        pixels_first: 
            bool

            Specifies whether the pixel dimensions are the first or last dimensions of the series.
            If not provided it is assumed the slice dimensions are the last dimensions
            of the array.

        inplace: 
            bool

            If True (default) the current pixel values in the series 
            are overwritten. If set to False, the new array is added to the series.
    
    Examples:
        ```ruby
        # Invert all images in a series:
        array, _ = series.array()
        series.set_array(-array)

        # Create a maximum intensity projection of the series.
        # Header information for the result is taken from the first image.
        # Results are saved in a new sibling series.
        array, data = series.array()
        array = np.amax(array, axis=0)
        data = np.squeeze(data[0,...])
        series.new_sibling().set_array(array, data)

        # Create a 2D maximum intensity projection along the SliceLocation direction.
        # Header information for the result is taken from the first slice location.
        # Current data of the series are overwritten.
        array, data = series.array(&#39;SliceLocation&#39;)
        array = np.amax(array, axis=0)
        data = np.squeeze(data[0,...])
        series.set_array(array, data)

        # In a series with multiple slice locations and inversion times,
        # replace all images for each slice location with that of the shortest inversion time.
        array, data = series.array([&#39;SliceLocation&#39;,&#39;InversionTime&#39;]) 
        for loc in range(array.shape[0]):               # loop over slice locations
            slice0 = np.squeeze(array[loc,0,0,:,:])     # get the slice with shortest TI 
            TI0 = data[loc,0,0].InversionTime           # get the TI of that slice
            for TI in range(array.shape[1]):            # loop over TIs
                array[loc,TI,0,:,:] = slice0            # replace each slice with shortest TI
                data[loc,TI,0].InversionTime = TI0      # replace each TI with shortest TI
        series.set_array(array, data)
        ```
    &#34;&#34;&#34;
    if pixels_first:    # Move to the end (default)
        array = np.moveaxis(array, 0, -1)
        array = np.moveaxis(array, 0, -1)
    if dataset is None:
        dataset = self.dataset()
    # Return with error message if dataset and array do not match.
    nr_of_slices = np.prod(array.shape[:-2])
    if nr_of_slices != np.prod(dataset.shape):
        message = &#39;Error in set_array(): array and dataset do not match&#39;
        message += &#39;\n Array has &#39; + str(nr_of_slices) + &#39; elements&#39;
        message += &#39;\n dataset has &#39; + str(np.prod(dataset.shape)) + &#39; elements&#39;
        message += &#39;\n Check if the keyword pixels_first is set correctly.&#39;
        self.dialog.error(message)
        raise ValueError(message)
    # If self is not a series, create a new series.
    if self.generation != 3:
        series = self.new_series()
    else:
        series = self
    # Reshape, copy instances and save slices.
    array = array.reshape((nr_of_slices, array.shape[-2], array.shape[-1])) # shape (i,x,y)
    dataset = dataset.reshape(nr_of_slices) # shape (i,)

    dataset = db.copy(dataset.tolist(), series, status=self.status)
    for i, instance in enumerate(dataset):
        self.status.progress(i, len(dataset), &#39;Writing array to file..&#39;)
        instance.set_array(array[i,...])
        if inplace: instance.remove() # delete?
       
    #for i, instance in enumerate(dataset):
    #    self.status.progress(i, len(dataset), &#39;Saving data..&#39;)
    #    instance.copy_to(series).set_array(array[i,...])
        # instance.set_array(array[i,...])
    #    if inplace: instance.remove() # delete?

    return series</code></pre>
</details>
</dd>
<dt id="dbdicom.classes.record.Record.in_memory"><code class="name flex">
<span>def <span class="ident">in_memory</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Check if the object has been read into memory</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def in_memory(self): # is_in_memory
    &#34;&#34;&#34;Check if the object has been read into memory&#34;&#34;&#34;

    return self.ds is not None</code></pre>
</details>
</dd>
<dt id="dbdicom.classes.record.Record.on_disk"><code class="name flex">
<span>def <span class="ident">on_disk</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def on_disk(self): # is_on_disk

    return self.ds is None</code></pre>
</details>
</dd>
<dt id="dbdicom.classes.record.Record.children"><code class="name flex">
<span>def <span class="ident">children</span></span>(<span>self, index=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>List of children</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def children(self, index=None, **kwargs):
    &#34;&#34;&#34;List of children&#34;&#34;&#34;

    if self.generation == 4: return []
    if self.in_memory():
        objects = utilities._filter(self.ds, **kwargs)
        if index is not None:
            if index &gt;= len(objects): 
                return
            else:
                return objects[index]
        return objects
    return self.records(generation=self.generation+1, index=index, **kwargs)</code></pre>
</details>
</dd>
<dt id="dbdicom.classes.record.Record.records"><code class="name flex">
<span>def <span class="ident">records</span></span>(<span>self, generation=0, index=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>A list of all records of a given generation corresponding to the record.</p>
<p>If generation is lower then that of the object,
all offspring of the given generation are returned.</p>
<p>If the generation is higher than that of the object,
the correspondong ancestor is return as a 1-element list.</p>
<p>Optionally the list can be filtered by index, or by providing a
list of DICOM KeyWords and values. In that case only objects
a returned that fulfill all criteria.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>generation</code></strong> :&ensp;<code>int</code></dt>
<dd>The generation to be returned (0 to 4)</dd>
<dt><strong><code>index</code></strong> :&ensp;<code>int</code></dt>
<dd>Index of the single object to be return</dd>
<dt><strong><code>kwargs</code></strong> :&ensp;<code>(Key, Value)</code></dt>
<dd>Conditions to filter the objects</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def records(self, generation=0, index=None, **kwargs):
    &#34;&#34;&#34;A list of all records of a given generation corresponding to the record.

    If generation is lower then that of the object, 
    all offspring of the given generation are returned.

    If the generation is higher than that of the object,
    the correspondong ancestor is return as a 1-element list.

    Optionally the list can be filtered by index, or by providing a 
    list of DICOM KeyWords and values. In that case only objects
    a returned that fulfill all criteria.
    
    Parameters
    ----------
    generation : int
        The generation to be returned (0 to 4)
    index : int
        Index of the single object to be return
    kwargs : (Key, Value)
        Conditions to filter the objects
    &#34;&#34;&#34;
    objects = []
    if generation == 0:
        obj = self.dicm.object(self.folder, generation=0)
        objects.append(obj)
    else:
        key = self.folder._columns[0:generation]
        data = self.data()
        if data.empty: 
            if index is None:
                return objects
            else:
                return
        column = data[key[-1]]
        rec_list = column.unique()
        if index is not None:
            rec_list = [rec_list[index]]
        for rec in rec_list:
            rec_data = data[column == rec]
            row = rec_data.iloc[0]
            obj = self.dicm.object(self.folder, row, generation)
            objects.append(obj)
    objects = utilities._filter(objects, **kwargs)
    if index is not None: return objects[0]
    return objects</code></pre>
</details>
</dd>
<dt id="dbdicom.classes.record.Record.patients"><code class="name flex">
<span>def <span class="ident">patients</span></span>(<span>self, index=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>A list of patients of the object</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def patients(self, index=None,  **kwargs):
    &#34;&#34;&#34;A list of patients of the object&#34;&#34;&#34;

    if self.generation==4: 
        return self.parent.parent.parent
    if self.generation==3:
        return self.parent.parent
    if self.generation==2:
        self.parent
    if self.generation==1:
        return
    return self.children(index=index, **kwargs)</code></pre>
</details>
</dd>
<dt id="dbdicom.classes.record.Record.studies"><code class="name flex">
<span>def <span class="ident">studies</span></span>(<span>self, index=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>A list of studies of the object</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def studies(self, index=None, **kwargs):
    &#34;&#34;&#34;A list of studies of the object&#34;&#34;&#34;

    if self.generation==4: 
        return self.parent.parent
    if self.generation==3:
        return self.parent
    if self.generation==2:
        return
    if self.generation==1:
        return self.children(index=index, **kwargs)
    objects = []
    for child in self.children():
        inst = child.studies(**kwargs)
        objects.extend(inst)
    if index is not None:
        if index &gt;= len(objects):
            return
        else:
            return objects[index]
    return objects</code></pre>
</details>
</dd>
<dt id="dbdicom.classes.record.Record.series"><code class="name flex">
<span>def <span class="ident">series</span></span>(<span>self, index=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>A list of series of the object</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def series(self, index=None, **kwargs):
    &#34;&#34;&#34;A list of series of the object&#34;&#34;&#34;

    if self.generation==4: 
        return self.parent
    if self.generation==3:
        return
    if self.generation==2:
        kids = self.children(index=index, **kwargs)
        return kids
    series = []
    for child in self.children():
        inst = child.series(**kwargs)
        series.extend(inst)
    if index is not None:
        if index &gt;= len(series):
            return
        else:
            return series[index]
    return series</code></pre>
</details>
</dd>
<dt id="dbdicom.classes.record.Record.instances"><code class="name flex">
<span>def <span class="ident">instances</span></span>(<span>self, index=None, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>A list of instances of the object</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def instances(self, index=None, **kwargs): # VERY slow - needs optimizing
    &#34;&#34;&#34;A list of instances of the object&#34;&#34;&#34;

    if self.generation==4: 
        return
    if self.generation==3:
        return self.children(index=index, **kwargs)
    instances = []
    for child in self.children():
        inst = child.instances(**kwargs)
        instances.extend(inst)
    if index is not None:
        if index &gt;= len(instances):
            return
        else:
            return instances[index]
    return instances       </code></pre>
</details>
</dd>
<dt id="dbdicom.classes.record.Record.new_child"><code class="name flex">
<span>def <span class="ident">new_child</span></span>(<span>self, **attributes)</span>
</code></dt>
<dd>
<div class="desc"><p>Creates a new child object</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def new_child(self, **attributes):
    &#34;&#34;&#34;Creates a new child object&#34;&#34;&#34;

    obj = self.dicm.new_child(self, **attributes)
    obj.read() # Why??
    return obj</code></pre>
</details>
</dd>
<dt id="dbdicom.classes.record.Record.new_sibling"><code class="name flex">
<span>def <span class="ident">new_sibling</span></span>(<span>self, **attributes)</span>
</code></dt>
<dd>
<div class="desc"><p>Creates a new sibling under the same parent.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def new_sibling(self, **attributes):
    &#34;&#34;&#34;
    Creates a new sibling under the same parent.
    &#34;&#34;&#34;
    if self.generation == 0:
        return
    else:
        return self.parent.new_child(**attributes)</code></pre>
</details>
</dd>
<dt id="dbdicom.classes.record.Record.new_pibling"><code class="name flex">
<span>def <span class="ident">new_pibling</span></span>(<span>self, **attributes)</span>
</code></dt>
<dd>
<div class="desc"><p>Creates a new sibling of parent.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def new_pibling(self, **attributes):
    &#34;&#34;&#34;
    Creates a new sibling of parent.
    &#34;&#34;&#34;
    if self.generation &lt;= 1:
        return
    else:
        return self.parent.new_sibling(**attributes)</code></pre>
</details>
</dd>
<dt id="dbdicom.classes.record.Record.new_cousin"><code class="name flex">
<span>def <span class="ident">new_cousin</span></span>(<span>self, **attributes)</span>
</code></dt>
<dd>
<div class="desc"><p>Creates a new sibling of parent.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def new_cousin(self, **attributes):
    &#34;&#34;&#34;
    Creates a new sibling of parent.
    &#34;&#34;&#34;
    if self.generation &lt;= 1:
        return
    else:
        return self.new_pibling().new_child(**attributes)</code></pre>
</details>
</dd>
<dt id="dbdicom.classes.record.Record.new_series"><code class="name flex">
<span>def <span class="ident">new_series</span></span>(<span>self, **attributes)</span>
</code></dt>
<dd>
<div class="desc"><p>Creates a new series under the same parent</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def new_series(self, **attributes):
    &#34;&#34;&#34;
    Creates a new series under the same parent
    &#34;&#34;&#34; 
    if self.generation &lt;= 1: 
        return self.new_child().new_series(**attributes)
    if self.generation == 2:
        return self.new_child(**attributes)
    if self.generation == 3:
        return self.new_sibling(**attributes)
    if self.generation == 4:
        return self.new_pibling(**attributes) </code></pre>
</details>
</dd>
<dt id="dbdicom.classes.record.Record.remove"><code class="name flex">
<span>def <span class="ident">remove</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Deletes the object.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def remove(self):
    &#34;&#34;&#34;Deletes the object. &#34;&#34;&#34; 

    files = self.files
    if files == []: 
        return
    self.folder.dataframe.loc[self.data().index,&#39;removed&#39;] = True</code></pre>
</details>
</dd>
<dt id="dbdicom.classes.record.Record.move_to"><code class="name flex">
<span>def <span class="ident">move_to</span></span>(<span>self, ancestor)</span>
</code></dt>
<dd>
<div class="desc"><p>move object to a new parent.</p>
<p>ancestor:any DICOM Class
If the object is not a parent, the missing
intermediate generations are automatically created.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def move_to(self, ancestor):
    &#34;&#34;&#34;move object to a new parent.
    
    ancestor:any DICOM Class
        If the object is not a parent, the missing 
        intermediate generations are automatically created.
    &#34;&#34;&#34;
    copy = self.copy_to(ancestor)
    self.remove()
    return copy</code></pre>
</details>
</dd>
<dt id="dbdicom.classes.record.Record.copy"><code class="name flex">
<span>def <span class="ident">copy</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a copy in the same parent</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def copy(self):
    &#34;&#34;&#34;Returns a copy in the same parent&#34;&#34;&#34;

    copy = self.copy_to(self.parent)
    if self.in_memory(): copy.read()
    return copy</code></pre>
</details>
</dd>
<dt id="dbdicom.classes.record.Record.merge_with"><code class="name flex">
<span>def <span class="ident">merge_with</span></span>(<span>self, obj, message=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def merge_with(self, obj, message=None): 

    if self.generation == 0: return
    if message is None:
        message = &#34;Merging &#34; + self.__class__.__name__ + &#39; &#39; + self.label()
    # replace by db.merge()
    return self._merge_with(obj, obj.parent, message=message)</code></pre>
</details>
</dd>
<dt id="dbdicom.classes.record.Record.copy_to"><code class="name flex">
<span>def <span class="ident">copy_to</span></span>(<span>self, ancestor, message=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def copy_to(self, ancestor, message=None):

    if self.generation == 0: return
    if message is None:
        message = &#34;Copying &#34; + self.__class__.__name__ + &#39; &#39; + self.label()
    copy = self.__class__(self.folder, UID=ancestor.UID)
    # replace by db.merge()
    return self._merge_with(copy, ancestor, message=message)</code></pre>
</details>
</dd>
<dt id="dbdicom.classes.record.Record.export"><code class="name flex">
<span>def <span class="ident">export</span></span>(<span>self, path)</span>
</code></dt>
<dd>
<div class="desc"><p>Export instances to an external folder.</p>
<p>The instance itself will not be removed from the DICOM folder.
Instead a copy of the file will be copied to the external folder.</p>
<h2 id="arguments">Arguments</h2>
<dl>
<dt><strong><code>path</code></strong> :&ensp;<code>str</code></dt>
<dd>path to an external folder. If not provided,
a window will prompt the user to select one.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def export(self, path):
    &#34;&#34;&#34;Export instances to an external folder.

    The instance itself will not be removed from the DICOM folder.
    Instead a copy of the file will be copied to the external folder.
    
    Arguments
    ---------
    path : str
        path to an external folder. If not provided,
        a window will prompt the user to select one.
    &#34;&#34;&#34;
    instances = self.instances()
    self.status.message(&#39;Exporting..&#39;)
    for i, instance in enumerate(instances):
        instance.export(path)
        self.status.progress(i,len(instances))
    self.status.hide()</code></pre>
</details>
</dd>
<dt id="dbdicom.classes.record.Record.save_OBSOLETE"><code class="name flex">
<span>def <span class="ident">save_OBSOLETE</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Save all instances of the record.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_OBSOLETE(self):
    &#34;&#34;&#34;Save all instances of the record.&#34;&#34;&#34;

    # Slow - edit df directly
    self.status.message(&#34;Saving all current instances..&#34;)
    instances = self.instances() 
    for i, instance in enumerate(instances):
        instance.save()
        self.status.progress(i, len(instances))
    self.status.hide()

    self.status.message(&#34;Deleting all removed instances..&#34;)
    if self.__class__.__name__ == &#39;Folder&#39;:
        data = self.folder.dataframe
    else:
        rows = self.folder.dataframe[self.key[-1]] == self.UID[-1]
        data = self.folder.dataframe[rows] 
    removed = data.removed[data.removed]
    files = [os.path.join(self.folder.path, p) for p in removed.index.tolist()]
    for i, file in enumerate(files): 
        os.remove(file)
        self.status.progress(i, len(files))
    self.folder.dataframe.drop(removed.index, inplace=True)
    self.status.hide()</code></pre>
</details>
</dd>
<dt id="dbdicom.classes.record.Record.save"><code class="name flex">
<span>def <span class="ident">save</span></span>(<span>self, message='Saving changes..')</span>
</code></dt>
<dd>
<div class="desc"><p>Save all instances of the record.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save(self, message = &#34;Saving changes..&#34;):
    &#34;&#34;&#34;Save all instances of the record.&#34;&#34;&#34;

    self.status.message(message)
    self.write()
    if self.generation == 0:
        data = self.folder.dataframe
    else:
        rows = self.folder.dataframe[self.key[-1]] == self.UID[-1]
        data = self.folder.dataframe[rows] 

    created = data.created[data.created]   
    removed = data.removed[data.removed]

    files = [os.path.join(self.folder.path, p) for p in removed.index.tolist()]
    for i, file in enumerate(files): 
        self.status.progress(i, len(files), message=&#39;Deleting removed files..&#39;)
        if os.path.exists(file): os.remove(file)
    #self.status.message(&#39;Clearing rapid access storage..&#39;)
    #npyfile = self.npy()
    #if os.path.exists(npyfile): os.remove(npyfile)
    self.status.message(&#39;Done saving..&#39;)
    self.folder.dataframe.loc[created.index, &#39;created&#39;] = False
    self.folder.dataframe.drop(removed.index, inplace=True)</code></pre>
</details>
</dd>
<dt id="dbdicom.classes.record.Record.restore"><code class="name flex">
<span>def <span class="ident">restore</span></span>(<span>self, message='Restoring saved state..')</span>
</code></dt>
<dd>
<div class="desc"><p>Restore all instances.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def restore(self, message = &#34;Restoring saved state..&#34;):
    &#34;&#34;&#34;
    Restore all instances.
    &#34;&#34;&#34;
    self.status.message(message)

    in_memory = self.in_memory() 
    self.clear()

    if self.generation == 0:
        data = self.folder.dataframe
    else:
        rows = self.folder.dataframe[self.key[-1]] == self.UID[-1]
        data = self.folder.dataframe[rows] 
    created = data.created[data.created]   
    removed = data.removed[data.removed]

    files = [os.path.join(self.folder.path, p) for p in created.index.tolist()]
    for i, file in enumerate(files): 
        self.status.progress(i, len(files), message=&#39;Deleting new files..&#39;)
        if os.path.exists(file): os.remove(file)
    self.status.hide()
    self.folder.dataframe.loc[removed.index, &#39;removed&#39;] = False
    self.folder.dataframe.drop(created.index, inplace=True)

    if in_memory: self.read()
    return self</code></pre>
</details>
</dd>
<dt id="dbdicom.classes.record.Record.restore_OBSOLETE"><code class="name flex">
<span>def <span class="ident">restore_OBSOLETE</span></span>(<span>self, message='Restoring..')</span>
</code></dt>
<dd>
<div class="desc"><p>Restore all instances.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def restore_OBSOLETE(self, message = &#39;Restoring..&#39;):
    &#34;&#34;&#34;
    Restore all instances.
    &#34;&#34;&#34;
    in_memory = self.in_memory() 
    self.clear()

    instances = self.instances()
    self.status.message(message)
    for i, instance in enumerate(instances):
        instance.restore()
        self.status.progress(i,len(instances))
    self.status.hide()

    if in_memory: self.read()
    return self</code></pre>
</details>
</dd>
<dt id="dbdicom.classes.record.Record.read_dataframe"><code class="name flex">
<span>def <span class="ident">read_dataframe</span></span>(<span>self, tags)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read_dataframe(self, tags):

    return utilities.dataframe(self.folder.path, self.files, tags, self.status)</code></pre>
</details>
</dd>
<dt id="dbdicom.classes.record.Record.read"><code class="name flex">
<span>def <span class="ident">read</span></span>(<span>self, message='Reading..')</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def read(self, message = &#39;Reading..&#39;):

    self.status.message(message)
    self.__dict__[&#39;ds&#39;] = self.children()
    for i, child in enumerate(self.ds):
        self.status.progress(i, len(self.ds))
        child.read()
    self.status.hide()</code></pre>
</details>
</dd>
<dt id="dbdicom.classes.record.Record.write"><code class="name flex">
<span>def <span class="ident">write</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def write(self):

    if self.ds is None: 
        return
    for i, child in enumerate(self.ds):
        self.status.progress(i, len(self.ds), message=&#39;Writing data..&#39;)
        child.write()
    self.status.hide()</code></pre>
</details>
</dd>
<dt id="dbdicom.classes.record.Record.clear"><code class="name flex">
<span>def <span class="ident">clear</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def clear(self):

    if self.ds is None: 
        return
    for child in self.ds:
        child.clear()
    self.ds = None</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="dbdicom.classes" href="index.html">dbdicom.classes</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="dbdicom.classes.record.Record" href="#dbdicom.classes.record.Record">Record</a></code></h4>
<ul class="two-column">
<li><code><a title="dbdicom.classes.record.Record.new_uid" href="#dbdicom.classes.record.Record.new_uid">new_uid</a></code></li>
<li><code><a title="dbdicom.classes.record.Record.data" href="#dbdicom.classes.record.Record.data">data</a></code></li>
<li><code><a title="dbdicom.classes.record.Record.dataset" href="#dbdicom.classes.record.Record.dataset">dataset</a></code></li>
<li><code><a title="dbdicom.classes.record.Record.array" href="#dbdicom.classes.record.Record.array">array</a></code></li>
<li><code><a title="dbdicom.classes.record.Record.npy" href="#dbdicom.classes.record.Record.npy">npy</a></code></li>
<li><code><a title="dbdicom.classes.record.Record.load_npy" href="#dbdicom.classes.record.Record.load_npy">load_npy</a></code></li>
<li><code><a title="dbdicom.classes.record.Record.save_npy" href="#dbdicom.classes.record.Record.save_npy">save_npy</a></code></li>
<li><code><a title="dbdicom.classes.record.Record.set_array" href="#dbdicom.classes.record.Record.set_array">set_array</a></code></li>
<li><code><a title="dbdicom.classes.record.Record.in_memory" href="#dbdicom.classes.record.Record.in_memory">in_memory</a></code></li>
<li><code><a title="dbdicom.classes.record.Record.on_disk" href="#dbdicom.classes.record.Record.on_disk">on_disk</a></code></li>
<li><code><a title="dbdicom.classes.record.Record.children" href="#dbdicom.classes.record.Record.children">children</a></code></li>
<li><code><a title="dbdicom.classes.record.Record.records" href="#dbdicom.classes.record.Record.records">records</a></code></li>
<li><code><a title="dbdicom.classes.record.Record.patients" href="#dbdicom.classes.record.Record.patients">patients</a></code></li>
<li><code><a title="dbdicom.classes.record.Record.studies" href="#dbdicom.classes.record.Record.studies">studies</a></code></li>
<li><code><a title="dbdicom.classes.record.Record.series" href="#dbdicom.classes.record.Record.series">series</a></code></li>
<li><code><a title="dbdicom.classes.record.Record.instances" href="#dbdicom.classes.record.Record.instances">instances</a></code></li>
<li><code><a title="dbdicom.classes.record.Record.new_child" href="#dbdicom.classes.record.Record.new_child">new_child</a></code></li>
<li><code><a title="dbdicom.classes.record.Record.new_sibling" href="#dbdicom.classes.record.Record.new_sibling">new_sibling</a></code></li>
<li><code><a title="dbdicom.classes.record.Record.new_pibling" href="#dbdicom.classes.record.Record.new_pibling">new_pibling</a></code></li>
<li><code><a title="dbdicom.classes.record.Record.new_cousin" href="#dbdicom.classes.record.Record.new_cousin">new_cousin</a></code></li>
<li><code><a title="dbdicom.classes.record.Record.new_series" href="#dbdicom.classes.record.Record.new_series">new_series</a></code></li>
<li><code><a title="dbdicom.classes.record.Record.remove" href="#dbdicom.classes.record.Record.remove">remove</a></code></li>
<li><code><a title="dbdicom.classes.record.Record.move_to" href="#dbdicom.classes.record.Record.move_to">move_to</a></code></li>
<li><code><a title="dbdicom.classes.record.Record.copy" href="#dbdicom.classes.record.Record.copy">copy</a></code></li>
<li><code><a title="dbdicom.classes.record.Record.merge_with" href="#dbdicom.classes.record.Record.merge_with">merge_with</a></code></li>
<li><code><a title="dbdicom.classes.record.Record.copy_to" href="#dbdicom.classes.record.Record.copy_to">copy_to</a></code></li>
<li><code><a title="dbdicom.classes.record.Record.export" href="#dbdicom.classes.record.Record.export">export</a></code></li>
<li><code><a title="dbdicom.classes.record.Record.save_OBSOLETE" href="#dbdicom.classes.record.Record.save_OBSOLETE">save_OBSOLETE</a></code></li>
<li><code><a title="dbdicom.classes.record.Record.save" href="#dbdicom.classes.record.Record.save">save</a></code></li>
<li><code><a title="dbdicom.classes.record.Record.restore" href="#dbdicom.classes.record.Record.restore">restore</a></code></li>
<li><code><a title="dbdicom.classes.record.Record.restore_OBSOLETE" href="#dbdicom.classes.record.Record.restore_OBSOLETE">restore_OBSOLETE</a></code></li>
<li><code><a title="dbdicom.classes.record.Record.read_dataframe" href="#dbdicom.classes.record.Record.read_dataframe">read_dataframe</a></code></li>
<li><code><a title="dbdicom.classes.record.Record.read" href="#dbdicom.classes.record.Record.read">read</a></code></li>
<li><code><a title="dbdicom.classes.record.Record.write" href="#dbdicom.classes.record.Record.write">write</a></code></li>
<li><code><a title="dbdicom.classes.record.Record.clear" href="#dbdicom.classes.record.Record.clear">clear</a></code></li>
<li><code><a title="dbdicom.classes.record.Record.generation" href="#dbdicom.classes.record.Record.generation">generation</a></code></li>
<li><code><a title="dbdicom.classes.record.Record.key" href="#dbdicom.classes.record.Record.key">key</a></code></li>
<li><code><a title="dbdicom.classes.record.Record.files" href="#dbdicom.classes.record.Record.files">files</a></code></li>
<li><code><a title="dbdicom.classes.record.Record.parent" href="#dbdicom.classes.record.Record.parent">parent</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>